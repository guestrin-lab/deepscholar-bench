qid,query,nuggets,supported_nuggets,partially_supported_nuggets,nuggets_metrics
2506.00085v1,"Write a Related Works section for an academic paper given the paper's abstract. Here is the paper abstract:
Large Language Models (LLMs) encode behaviors such as refusal within their
activation space, yet identifying these behaviors remains a significant
challenge. Existing methods often rely on predefined refusal templates
detectable in output tokens or require manual analysis. We introduce
\textbf{COSMIC} (Cosine Similarity Metrics for Inversion of Concepts), an
automated framework for direction selection that identifies viable steering
directions and target layers using cosine similarity - entirely independent of
model outputs. COSMIC achieves steering performance comparable to prior methods
without requiring assumptions about a model's refusal behavior, such as the
presence of specific refusal tokens. It reliably identifies refusal directions
in adversarial settings and weakly aligned models, and is capable of steering
such models toward safer behavior with minimal increase in false refusals,
demonstrating robustness across a wide range of alignment conditions.","[{'text': 'Refusal behaviors are encoded in LLM activation space', 'importance': 'vital', 'assignment': 'support'}, {'text': 'Interventions can directly modulate refusal in activation space', 'importance': 'vital', 'assignment': 'support'}, {'text': 'Similarity-based scores can target intervention layers', 'importance': 'vital', 'assignment': 'support'}, {'text': 'Model behaviors often linearly encoded in activation space', 'importance': 'vital', 'assignment': 'support'}, {'text': 'LLM alignment often uses fine-tuning and RLHF', 'importance': 'okay', 'assignment': 'support'}, {'text': 'Fine-tuning and adversarial prompts can bypass refusal mechanisms', 'importance': 'okay', 'assignment': 'support'}, {'text': 'Contrastive data pairs extract feature directions for behavior steering', 'importance': 'okay', 'assignment': 'support'}, {'text': 'Concept removal uses Representation Engineering and Contrastive Activation Addition', 'importance': 'okay', 'assignment': 'support'}, {'text': 'Refusal behaviors sometimes modeled as affine functions', 'importance': 'okay', 'assignment': 'support'}, {'text': 'Mechanistic interpretability uses sparse autoencoders, weight analysis, circuit analysis', 'importance': 'okay', 'assignment': 'support'}]","[{'text': 'Refusal behaviors are encoded in LLM activation space', 'importance': 'vital', 'assignment': 'support'}, {'text': 'Interventions can directly modulate refusal in activation space', 'importance': 'vital', 'assignment': 'support'}, {'text': 'Similarity-based scores can target intervention layers', 'importance': 'vital', 'assignment': 'support'}, {'text': 'Model behaviors often linearly encoded in activation space', 'importance': 'vital', 'assignment': 'support'}, {'text': 'LLM alignment often uses fine-tuning and RLHF', 'importance': 'okay', 'assignment': 'support'}, {'text': 'Fine-tuning and adversarial prompts can bypass refusal mechanisms', 'importance': 'okay', 'assignment': 'support'}, {'text': 'Contrastive data pairs extract feature directions for behavior steering', 'importance': 'okay', 'assignment': 'support'}, {'text': 'Concept removal uses Representation Engineering and Contrastive Activation Addition', 'importance': 'okay', 'assignment': 'support'}, {'text': 'Refusal behaviors sometimes modeled as affine functions', 'importance': 'okay', 'assignment': 'support'}, {'text': 'Mechanistic interpretability uses sparse autoencoders, weight analysis, circuit analysis', 'importance': 'okay', 'assignment': 'support'}]","[{'text': 'Refusal behaviors are encoded in LLM activation space', 'importance': 'vital', 'assignment': 'support'}, {'text': 'Interventions can directly modulate refusal in activation space', 'importance': 'vital', 'assignment': 'support'}, {'text': 'Similarity-based scores can target intervention layers', 'importance': 'vital', 'assignment': 'support'}, {'text': 'Model behaviors often linearly encoded in activation space', 'importance': 'vital', 'assignment': 'support'}, {'text': 'LLM alignment often uses fine-tuning and RLHF', 'importance': 'okay', 'assignment': 'support'}, {'text': 'Fine-tuning and adversarial prompts can bypass refusal mechanisms', 'importance': 'okay', 'assignment': 'support'}, {'text': 'Contrastive data pairs extract feature directions for behavior steering', 'importance': 'okay', 'assignment': 'support'}, {'text': 'Concept removal uses Representation Engineering and Contrastive Activation Addition', 'importance': 'okay', 'assignment': 'support'}, {'text': 'Refusal behaviors sometimes modeled as affine functions', 'importance': 'okay', 'assignment': 'support'}, {'text': 'Mechanistic interpretability uses sparse autoencoders, weight analysis, circuit analysis', 'importance': 'okay', 'assignment': 'support'}]","{'strict_vital_score': 1.0, 'strict_all_score': 1.0, 'vital_score': 1.0, 'all_score': 1.0}"
