{
  "qid": "2505.24334v1",
  "query": "Write a Related Works section for an academic paper given the paper's abstract. Here is the paper abstract:\nIn the era of intelligent manufacturing, anomaly detection has become\nessential for maintaining quality control on modern production lines. However,\nwhile many existing models show promising performance, they are often too\nlarge, computationally demanding, and impractical to deploy on\nresource-constrained embedded devices that can be easily installed on the\nproduction lines of Small and Medium Enterprises (SMEs). To bridge this gap, we\npresent KairosAD, a novel supervised approach that uses the power of the Mobile\nSegment Anything Model (MobileSAM) for image-based anomaly detection. KairosAD\nhas been evaluated on the two well-known industrial anomaly detection datasets,\ni.e., MVTec-AD and ViSA. The results show that KairosAD requires 78% fewer\nparameters and boasts a 4x faster inference time compared to the leading\nstate-of-the-art model, while maintaining comparable AUROC performance. We\ndeployed KairosAD on two embedded devices, the NVIDIA Jetson NX, and the NVIDIA\nJetson AGX. Finally, KairosAD was successfully installed and tested on the real\nproduction line of the Industrial Computer Engineering Laboratory (ICE Lab) at\nthe University of Verona. The code is available at\nhttps://github.com/intelligolabs/KairosAD.",
  "nuggets": [
    {
      "text": "Industrial anomaly detection is a well-studied field",
      "importance": "vital",
      "assignment": "support"
    },
    {
      "text": "Reconstruction-based methods struggle with complex industrial textures",
      "importance": "vital",
      "assignment": "support"
    },
    {
      "text": "Memory bank approaches like PatchCore store patch-level features for detection",
      "importance": "vital",
      "assignment": "support"
    },
    {
      "text": "Memory bank methods are computationally intensive and memory-heavy",
      "importance": "vital",
      "assignment": "support"
    },
    {
      "text": "STLM is an efficient industrial anomaly detection model using feature distillation and contrastive learning",
      "importance": "vital",
      "assignment": "support"
    },
    {
      "text": "KairosAD uses a single-branch design for image-level anomaly detection",
      "importance": "vital",
      "assignment": "partial_support"
    },
    {
      "text": "KairosAD is optimized for efficiency and real-time deployment",
      "importance": "vital",
      "assignment": "partial_support"
    },
    {
      "text": "Foundation models like CLIP, SAM, and DINO are used in vision tasks",
      "importance": "vital",
      "assignment": "support"
    },
    {
      "text": "SAM is a promptable segmentation model generalizing across diverse images",
      "importance": "vital",
      "assignment": "support"
    },
    {
      "text": "MobileSAM is an efficient variant of SAM for edge devices",
      "importance": "vital",
      "assignment": "support"
    },
    {
      "text": "MobileSAM reduces computational demands while maintaining performance",
      "importance": "vital",
      "assignment": "support"
    },
    {
      "text": "MobileSAM and similar models enable segmentation and anomaly detection on embedded devices",
      "importance": "vital",
      "assignment": "partial_support"
    },
    {
      "text": "Efficient vision Transformers broaden use in resource-constrained settings",
      "importance": "vital",
      "assignment": "support"
    },
    {
      "text": "KairosAD leverages MobileSAM for lightweight, effective feature extraction",
      "importance": "vital",
      "assignment": "support"
    },
    {
      "text": "Industrial image data presents unique challenges for anomaly detection",
      "importance": "okay",
      "assignment": "support"
    },
    {
      "text": "Image reconstruction methods use autoencoders, VAEs, and GANs for anomaly detection",
      "importance": "okay",
      "assignment": "support"
    },
    {
      "text": "SoftPatch filters patch features to improve robustness over PatchCore",
      "importance": "okay",
      "assignment": "support"
    },
    {
      "text": "STLM uses a two-branch architecture for detection and localization",
      "importance": "okay",
      "assignment": "support"
    },
    {
      "text": "CLIP aligns image and text embeddings for zero-shot classification",
      "importance": "okay",
      "assignment": "support"
    },
    {
      "text": "DINO uses self-supervised learning with Vision Transformers for robust features",
      "importance": "okay",
      "assignment": "support"
    },
    {
      "text": "Efficient deep learning techniques include pruning, quantization, and knowledge distillation",
      "importance": "okay",
      "assignment": "support"
    },
    {
      "text": "Neural Architecture Search and attention mechanisms help create lightweight models",
      "importance": "okay",
      "assignment": "support"
    },
    {
      "text": "Transformers and attention mechanisms are adapted for vision tasks",
      "importance": "okay",
      "assignment": "support"
    }
  ],
  "supported_nuggets": [
    {
      "text": "Industrial anomaly detection is a well-studied field",
      "importance": "vital",
      "assignment": "support"
    },
    {
      "text": "Reconstruction-based methods struggle with complex industrial textures",
      "importance": "vital",
      "assignment": "support"
    },
    {
      "text": "Memory bank approaches like PatchCore store patch-level features for detection",
      "importance": "vital",
      "assignment": "support"
    },
    {
      "text": "Memory bank methods are computationally intensive and memory-heavy",
      "importance": "vital",
      "assignment": "support"
    },
    {
      "text": "STLM is an efficient industrial anomaly detection model using feature distillation and contrastive learning",
      "importance": "vital",
      "assignment": "support"
    },
    {
      "text": "Foundation models like CLIP, SAM, and DINO are used in vision tasks",
      "importance": "vital",
      "assignment": "support"
    },
    {
      "text": "SAM is a promptable segmentation model generalizing across diverse images",
      "importance": "vital",
      "assignment": "support"
    },
    {
      "text": "MobileSAM is an efficient variant of SAM for edge devices",
      "importance": "vital",
      "assignment": "support"
    },
    {
      "text": "MobileSAM reduces computational demands while maintaining performance",
      "importance": "vital",
      "assignment": "support"
    },
    {
      "text": "Efficient vision Transformers broaden use in resource-constrained settings",
      "importance": "vital",
      "assignment": "support"
    },
    {
      "text": "KairosAD leverages MobileSAM for lightweight, effective feature extraction",
      "importance": "vital",
      "assignment": "support"
    },
    {
      "text": "Industrial image data presents unique challenges for anomaly detection",
      "importance": "okay",
      "assignment": "support"
    },
    {
      "text": "Image reconstruction methods use autoencoders, VAEs, and GANs for anomaly detection",
      "importance": "okay",
      "assignment": "support"
    },
    {
      "text": "SoftPatch filters patch features to improve robustness over PatchCore",
      "importance": "okay",
      "assignment": "support"
    },
    {
      "text": "STLM uses a two-branch architecture for detection and localization",
      "importance": "okay",
      "assignment": "support"
    },
    {
      "text": "CLIP aligns image and text embeddings for zero-shot classification",
      "importance": "okay",
      "assignment": "support"
    },
    {
      "text": "DINO uses self-supervised learning with Vision Transformers for robust features",
      "importance": "okay",
      "assignment": "support"
    },
    {
      "text": "Efficient deep learning techniques include pruning, quantization, and knowledge distillation",
      "importance": "okay",
      "assignment": "support"
    },
    {
      "text": "Neural Architecture Search and attention mechanisms help create lightweight models",
      "importance": "okay",
      "assignment": "support"
    },
    {
      "text": "Transformers and attention mechanisms are adapted for vision tasks",
      "importance": "okay",
      "assignment": "support"
    }
  ],
  "partially_supported_nuggets": [
    {
      "text": "Industrial anomaly detection is a well-studied field",
      "importance": "vital",
      "assignment": "support"
    },
    {
      "text": "Reconstruction-based methods struggle with complex industrial textures",
      "importance": "vital",
      "assignment": "support"
    },
    {
      "text": "Memory bank approaches like PatchCore store patch-level features for detection",
      "importance": "vital",
      "assignment": "support"
    },
    {
      "text": "Memory bank methods are computationally intensive and memory-heavy",
      "importance": "vital",
      "assignment": "support"
    },
    {
      "text": "STLM is an efficient industrial anomaly detection model using feature distillation and contrastive learning",
      "importance": "vital",
      "assignment": "support"
    },
    {
      "text": "KairosAD uses a single-branch design for image-level anomaly detection",
      "importance": "vital",
      "assignment": "partial_support"
    },
    {
      "text": "KairosAD is optimized for efficiency and real-time deployment",
      "importance": "vital",
      "assignment": "partial_support"
    },
    {
      "text": "Foundation models like CLIP, SAM, and DINO are used in vision tasks",
      "importance": "vital",
      "assignment": "support"
    },
    {
      "text": "SAM is a promptable segmentation model generalizing across diverse images",
      "importance": "vital",
      "assignment": "support"
    },
    {
      "text": "MobileSAM is an efficient variant of SAM for edge devices",
      "importance": "vital",
      "assignment": "support"
    },
    {
      "text": "MobileSAM reduces computational demands while maintaining performance",
      "importance": "vital",
      "assignment": "support"
    },
    {
      "text": "MobileSAM and similar models enable segmentation and anomaly detection on embedded devices",
      "importance": "vital",
      "assignment": "partial_support"
    },
    {
      "text": "Efficient vision Transformers broaden use in resource-constrained settings",
      "importance": "vital",
      "assignment": "support"
    },
    {
      "text": "KairosAD leverages MobileSAM for lightweight, effective feature extraction",
      "importance": "vital",
      "assignment": "support"
    },
    {
      "text": "Industrial image data presents unique challenges for anomaly detection",
      "importance": "okay",
      "assignment": "support"
    },
    {
      "text": "Image reconstruction methods use autoencoders, VAEs, and GANs for anomaly detection",
      "importance": "okay",
      "assignment": "support"
    },
    {
      "text": "SoftPatch filters patch features to improve robustness over PatchCore",
      "importance": "okay",
      "assignment": "support"
    },
    {
      "text": "STLM uses a two-branch architecture for detection and localization",
      "importance": "okay",
      "assignment": "support"
    },
    {
      "text": "CLIP aligns image and text embeddings for zero-shot classification",
      "importance": "okay",
      "assignment": "support"
    },
    {
      "text": "DINO uses self-supervised learning with Vision Transformers for robust features",
      "importance": "okay",
      "assignment": "support"
    },
    {
      "text": "Efficient deep learning techniques include pruning, quantization, and knowledge distillation",
      "importance": "okay",
      "assignment": "support"
    },
    {
      "text": "Neural Architecture Search and attention mechanisms help create lightweight models",
      "importance": "okay",
      "assignment": "support"
    },
    {
      "text": "Transformers and attention mechanisms are adapted for vision tasks",
      "importance": "okay",
      "assignment": "support"
    }
  ],
  "nuggets_metrics": {
    "strict_vital_score": 0.7857142857142857,
    "strict_all_score": 0.8695652173913043,
    "vital_score": 0.8928571428571429,
    "all_score": 0.9347826086956522
  }
}