qid,query,nuggets,supported_nuggets,partially_supported_nuggets,nuggets_metrics
2505.22167v1,"Write a Related Works section for an academic paper given the paper's abstract. Here is the paper abstract:
Diffusion transformers (DiT) have demonstrated exceptional performance in
video generation. However, their large number of parameters and high
computational complexity limit their deployment on edge devices. Quantization
can reduce storage requirements and accelerate inference by lowering the
bit-width of model parameters. Yet, existing quantization methods for image
generation models do not generalize well to video generation tasks. We identify
two primary challenges: the loss of information during quantization and the
misalignment between optimization objectives and the unique requirements of
video generation. To address these challenges, we present Q-VDiT, a
quantization framework specifically designed for video DiT models. From the
quantization perspective, we propose the Token-aware Quantization Estimator
(TQE), which compensates for quantization errors in both the token and feature
dimensions. From the optimization perspective, we introduce Temporal
Maintenance Distillation (TMD), which preserves the spatiotemporal correlations
between frames and enables the optimization of each frame with respect to the
overall video context. Our W3A6 Q-VDiT achieves a scene consistency of 23.40,
setting a new benchmark and outperforming current state-of-the-art quantization
methods by 1.9$\times$. Code will be available at
https://github.com/cantbebetter2/Q-VDiT.","[{'text': 'Diffusion transformers (DiT) excel in video generation tasks', 'importance': 'vital', 'assignment': 'not_support'}, {'text': 'DiT models have high parameter counts and computational complexity', 'importance': 'vital', 'assignment': 'not_support'}, {'text': 'Quantization reduces model size and accelerates inference', 'importance': 'vital', 'assignment': 'not_support'}, {'text': 'Existing quantization methods target image generation, not video', 'importance': 'vital', 'assignment': 'support'}, {'text': 'Video generation quantization faces information loss and optimization misalignment', 'importance': 'vital', 'assignment': 'partial_support'}, {'text': 'Q-VDiT is a quantization framework for video DiT models', 'importance': 'vital', 'assignment': 'not_support'}, {'text': 'Diffusion models generate high-quality images via denoising Gaussian noise', 'importance': 'okay', 'assignment': 'support'}, {'text': 'Q-DM, BinaryDM, BiDM, TerDiT use quantization-aware training for diffusion models', 'importance': 'okay', 'assignment': 'support'}, {'text': 'Q-Diffusion, PTQ4DM, PTQ-D, TFMQ-DM, QuEST, EfficientDM, MixDQ focus on Unet-based diffusion quantization', 'importance': 'okay', 'assignment': 'support'}, {'text': 'Q-DiT, PTQ4DiT, SVDQuant, ViDiT-Q address diffusion transformer quantization', 'importance': 'okay', 'assignment': 'support'}, {'text': 'Current quantization methods require extensive training or focus on images', 'importance': 'okay', 'assignment': 'support'}, {'text': 'Token-aware Quantization Estimator (TQE) compensates for token and feature quantization errors', 'importance': 'okay', 'assignment': 'not_support'}, {'text': 'Temporal Maintenance Distillation (TMD) preserves spatiotemporal frame correlations', 'importance': 'okay', 'assignment': 'not_support'}, {'text': 'Q-VDiT achieves state-of-the-art scene consistency and outperforms prior methods', 'importance': 'okay', 'assignment': 'not_support'}]","[{'text': 'Existing quantization methods target image generation, not video', 'importance': 'vital', 'assignment': 'support'}, {'text': 'Diffusion models generate high-quality images via denoising Gaussian noise', 'importance': 'okay', 'assignment': 'support'}, {'text': 'Q-DM, BinaryDM, BiDM, TerDiT use quantization-aware training for diffusion models', 'importance': 'okay', 'assignment': 'support'}, {'text': 'Q-Diffusion, PTQ4DM, PTQ-D, TFMQ-DM, QuEST, EfficientDM, MixDQ focus on Unet-based diffusion quantization', 'importance': 'okay', 'assignment': 'support'}, {'text': 'Q-DiT, PTQ4DiT, SVDQuant, ViDiT-Q address diffusion transformer quantization', 'importance': 'okay', 'assignment': 'support'}, {'text': 'Current quantization methods require extensive training or focus on images', 'importance': 'okay', 'assignment': 'support'}]","[{'text': 'Existing quantization methods target image generation, not video', 'importance': 'vital', 'assignment': 'support'}, {'text': 'Video generation quantization faces information loss and optimization misalignment', 'importance': 'vital', 'assignment': 'partial_support'}, {'text': 'Diffusion models generate high-quality images via denoising Gaussian noise', 'importance': 'okay', 'assignment': 'support'}, {'text': 'Q-DM, BinaryDM, BiDM, TerDiT use quantization-aware training for diffusion models', 'importance': 'okay', 'assignment': 'support'}, {'text': 'Q-Diffusion, PTQ4DM, PTQ-D, TFMQ-DM, QuEST, EfficientDM, MixDQ focus on Unet-based diffusion quantization', 'importance': 'okay', 'assignment': 'support'}, {'text': 'Q-DiT, PTQ4DiT, SVDQuant, ViDiT-Q address diffusion transformer quantization', 'importance': 'okay', 'assignment': 'support'}, {'text': 'Current quantization methods require extensive training or focus on images', 'importance': 'okay', 'assignment': 'support'}]","{'strict_vital_score': 0.16666666666666666, 'strict_all_score': 0.42857142857142855, 'vital_score': 0.25, 'all_score': 0.4642857142857143}"
