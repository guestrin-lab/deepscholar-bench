qid,query,nuggets,supported_nuggets,partially_supported_nuggets,nuggets_metrics
2506.01833v1,"Write a Related Works section for an academic paper given the paper's abstract. Here is the paper abstract:
Inspired by the success of unsupervised pre-training paradigms, researchers
have applied these approaches to DNA pre-training. However, we argue that these
approaches alone yield suboptimal results because pure DNA sequences lack
sufficient information, since their functions are regulated by genomic profiles
like chromatin accessibility. Here, we demonstrate that supervised training for
genomic profile prediction serves as a more effective alternative to pure
sequence pre-training. Furthermore, considering the multi-species and
multi-profile nature of genomic profile prediction, we introduce our
$\textbf{S}$pecies-$\textbf{P}$rofile $\textbf{A}$daptive
$\textbf{C}$ollaborative $\textbf{E}$xperts (SPACE) that leverages Mixture of
Experts (MoE) to better capture the relationships between DNA sequences across
different species and genomic profiles, thereby learning more effective DNA
representations. Through extensive experiments across various tasks, our model
achieves state-of-the-art performance, establishing that DNA models trained
with supervised genomic profiles serve as powerful DNA representation learners.
The code is available at https://github.com/ZhuJiwei111/SPACE.","[{'text': 'Supervised genomic profile models predict functional profiles from DNA sequences', 'importance': 'vital', 'assignment': 'support'}, {'text': 'Unsupervised DNA foundation models adapt NLP pre-training to DNA sequences', 'importance': 'vital', 'assignment': 'support'}, {'text': 'Little systematic comparison between unsupervised and supervised DNA models', 'importance': 'vital', 'assignment': 'support'}, {'text': 'MoE enables dynamic learning of species-specific and shared genomic features', 'importance': 'vital', 'assignment': 'support'}, {'text': 'DeepSEA pioneered CNN-based multi-task genomic profile prediction', 'importance': 'okay', 'assignment': 'support'}, {'text': 'Enformer uses hybrid Transformer-CNN for state-of-the-art genomic profile prediction', 'importance': 'okay', 'assignment': 'support'}, {'text': 'Genomic profile models use shared encoders with independent prediction heads', 'importance': 'okay', 'assignment': 'support'}, {'text': 'Few studies assess if intermediate representations capture biological patterns', 'importance': 'okay', 'assignment': 'support'}, {'text': 'DNABERT introduced BERT-style masked language modeling for DNA', 'importance': 'okay', 'assignment': 'support'}, {'text': 'Subsequent unsupervised models use MLM or NTP objectives for DNA', 'importance': 'okay', 'assignment': 'support'}, {'text': 'Unsupervised models optimize data, architectures, and tokenization strategies', 'importance': 'okay', 'assignment': 'support'}, {'text': 'MoE selectively activates expert networks via sparse routing', 'importance': 'okay', 'assignment': 'support'}, {'text': 'MoE improves parameter efficiency and model capacity in Transformers', 'importance': 'okay', 'assignment': 'support'}, {'text': 'MoE is implemented by replacing FFNs in Transformer architectures', 'importance': 'okay', 'assignment': 'support'}]","[{'text': 'Supervised genomic profile models predict functional profiles from DNA sequences', 'importance': 'vital', 'assignment': 'support'}, {'text': 'Unsupervised DNA foundation models adapt NLP pre-training to DNA sequences', 'importance': 'vital', 'assignment': 'support'}, {'text': 'Little systematic comparison between unsupervised and supervised DNA models', 'importance': 'vital', 'assignment': 'support'}, {'text': 'MoE enables dynamic learning of species-specific and shared genomic features', 'importance': 'vital', 'assignment': 'support'}, {'text': 'DeepSEA pioneered CNN-based multi-task genomic profile prediction', 'importance': 'okay', 'assignment': 'support'}, {'text': 'Enformer uses hybrid Transformer-CNN for state-of-the-art genomic profile prediction', 'importance': 'okay', 'assignment': 'support'}, {'text': 'Genomic profile models use shared encoders with independent prediction heads', 'importance': 'okay', 'assignment': 'support'}, {'text': 'Few studies assess if intermediate representations capture biological patterns', 'importance': 'okay', 'assignment': 'support'}, {'text': 'DNABERT introduced BERT-style masked language modeling for DNA', 'importance': 'okay', 'assignment': 'support'}, {'text': 'Subsequent unsupervised models use MLM or NTP objectives for DNA', 'importance': 'okay', 'assignment': 'support'}, {'text': 'Unsupervised models optimize data, architectures, and tokenization strategies', 'importance': 'okay', 'assignment': 'support'}, {'text': 'MoE selectively activates expert networks via sparse routing', 'importance': 'okay', 'assignment': 'support'}, {'text': 'MoE improves parameter efficiency and model capacity in Transformers', 'importance': 'okay', 'assignment': 'support'}, {'text': 'MoE is implemented by replacing FFNs in Transformer architectures', 'importance': 'okay', 'assignment': 'support'}]","[{'text': 'Supervised genomic profile models predict functional profiles from DNA sequences', 'importance': 'vital', 'assignment': 'support'}, {'text': 'Unsupervised DNA foundation models adapt NLP pre-training to DNA sequences', 'importance': 'vital', 'assignment': 'support'}, {'text': 'Little systematic comparison between unsupervised and supervised DNA models', 'importance': 'vital', 'assignment': 'support'}, {'text': 'MoE enables dynamic learning of species-specific and shared genomic features', 'importance': 'vital', 'assignment': 'support'}, {'text': 'DeepSEA pioneered CNN-based multi-task genomic profile prediction', 'importance': 'okay', 'assignment': 'support'}, {'text': 'Enformer uses hybrid Transformer-CNN for state-of-the-art genomic profile prediction', 'importance': 'okay', 'assignment': 'support'}, {'text': 'Genomic profile models use shared encoders with independent prediction heads', 'importance': 'okay', 'assignment': 'support'}, {'text': 'Few studies assess if intermediate representations capture biological patterns', 'importance': 'okay', 'assignment': 'support'}, {'text': 'DNABERT introduced BERT-style masked language modeling for DNA', 'importance': 'okay', 'assignment': 'support'}, {'text': 'Subsequent unsupervised models use MLM or NTP objectives for DNA', 'importance': 'okay', 'assignment': 'support'}, {'text': 'Unsupervised models optimize data, architectures, and tokenization strategies', 'importance': 'okay', 'assignment': 'support'}, {'text': 'MoE selectively activates expert networks via sparse routing', 'importance': 'okay', 'assignment': 'support'}, {'text': 'MoE improves parameter efficiency and model capacity in Transformers', 'importance': 'okay', 'assignment': 'support'}, {'text': 'MoE is implemented by replacing FFNs in Transformer architectures', 'importance': 'okay', 'assignment': 'support'}]","{'strict_vital_score': 1.0, 'strict_all_score': 1.0, 'vital_score': 1.0, 'all_score': 1.0}"
