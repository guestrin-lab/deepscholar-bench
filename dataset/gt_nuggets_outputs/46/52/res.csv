qid,query,nuggets,supported_nuggets,partially_supported_nuggets,nuggets_metrics
2505.19307v1,"Write a Related Works section for an academic paper given the paper's abstract. Here is the paper abstract:
Neural retrieval models excel in Web search, but their training requires
substantial amounts of labeled query-document pairs, which are costly to
obtain. With the widespread availability of Web document collections like
ClueWeb22, synthetic queries generated by large language models offer a
scalable alternative. Still, synthetic training queries often vary in quality,
which leads to suboptimal downstream retrieval performance. Existing methods
typically filter out noisy query-document pairs based on signals from an
external re-ranker. In contrast, we propose a framework that leverages Direct
Preference Optimization (DPO) to integrate ranking signals into the query
generation process, aiming to directly optimize the model towards generating
high-quality queries that maximize downstream retrieval effectiveness.
Experiments show higher ranker-assessed relevance between query-document pairs
after DPO, leading to stronger downstream performance on the MS~MARCO benchmark
when compared to baseline models trained with synthetic data.","[{'text': 'Synthetic queries from documents are widely used for model training', 'importance': 'vital', 'assignment': 'support'}, {'text': 'Filtering hallucinated queries enhances downstream retrieval performance', 'importance': 'vital', 'assignment': 'support'}, {'text': 'LLMs enable few-shot synthetic query generation (e.g., InPars, Promptagator)', 'importance': 'vital', 'assignment': 'support'}, {'text': 'InPars filters queries by generation probability; InPars-v2 uses supervised ranker', 'importance': 'vital', 'assignment': 'support'}, {'text': 'Reinforcement learning (e.g., TPPO) optimizes query generation with token-level rewards', 'importance': 'vital', 'assignment': 'support'}, {'text': 'Direct Preference Optimization (DPO) integrates ranking signals into query generation', 'importance': 'vital', 'assignment': 'not_support'}, {'text': 'DPO directly optimizes for high-quality, retrieval-effective queries', 'importance': 'vital', 'assignment': 'not_support'}, {'text': 'Transformer-based bi-encoders are standard for dense neural retrieval', 'importance': 'okay', 'assignment': 'support'}, {'text': 'Contrastive objectives and hard negative mining improve retrieval training', 'importance': 'okay', 'assignment': 'support'}, {'text': 'Retrieval-aligned pre-training on in-domain corpora boosts effectiveness', 'importance': 'okay', 'assignment': 'support'}, {'text': 'Doc2Query and DocT5Query expand document representations with synthetic queries', 'importance': 'okay', 'assignment': 'support'}, {'text': 'Gecko iteratively refines synthetic queries via retrieval, re-ranking, relabeling', 'importance': 'okay', 'assignment': 'support'}, {'text': 'TPPO targets interactive query suggestion, not offline document-based generation', 'importance': 'okay', 'assignment': 'support'}]","[{'text': 'Synthetic queries from documents are widely used for model training', 'importance': 'vital', 'assignment': 'support'}, {'text': 'Filtering hallucinated queries enhances downstream retrieval performance', 'importance': 'vital', 'assignment': 'support'}, {'text': 'LLMs enable few-shot synthetic query generation (e.g., InPars, Promptagator)', 'importance': 'vital', 'assignment': 'support'}, {'text': 'InPars filters queries by generation probability; InPars-v2 uses supervised ranker', 'importance': 'vital', 'assignment': 'support'}, {'text': 'Reinforcement learning (e.g., TPPO) optimizes query generation with token-level rewards', 'importance': 'vital', 'assignment': 'support'}, {'text': 'Transformer-based bi-encoders are standard for dense neural retrieval', 'importance': 'okay', 'assignment': 'support'}, {'text': 'Contrastive objectives and hard negative mining improve retrieval training', 'importance': 'okay', 'assignment': 'support'}, {'text': 'Retrieval-aligned pre-training on in-domain corpora boosts effectiveness', 'importance': 'okay', 'assignment': 'support'}, {'text': 'Doc2Query and DocT5Query expand document representations with synthetic queries', 'importance': 'okay', 'assignment': 'support'}, {'text': 'Gecko iteratively refines synthetic queries via retrieval, re-ranking, relabeling', 'importance': 'okay', 'assignment': 'support'}, {'text': 'TPPO targets interactive query suggestion, not offline document-based generation', 'importance': 'okay', 'assignment': 'support'}]","[{'text': 'Synthetic queries from documents are widely used for model training', 'importance': 'vital', 'assignment': 'support'}, {'text': 'Filtering hallucinated queries enhances downstream retrieval performance', 'importance': 'vital', 'assignment': 'support'}, {'text': 'LLMs enable few-shot synthetic query generation (e.g., InPars, Promptagator)', 'importance': 'vital', 'assignment': 'support'}, {'text': 'InPars filters queries by generation probability; InPars-v2 uses supervised ranker', 'importance': 'vital', 'assignment': 'support'}, {'text': 'Reinforcement learning (e.g., TPPO) optimizes query generation with token-level rewards', 'importance': 'vital', 'assignment': 'support'}, {'text': 'Transformer-based bi-encoders are standard for dense neural retrieval', 'importance': 'okay', 'assignment': 'support'}, {'text': 'Contrastive objectives and hard negative mining improve retrieval training', 'importance': 'okay', 'assignment': 'support'}, {'text': 'Retrieval-aligned pre-training on in-domain corpora boosts effectiveness', 'importance': 'okay', 'assignment': 'support'}, {'text': 'Doc2Query and DocT5Query expand document representations with synthetic queries', 'importance': 'okay', 'assignment': 'support'}, {'text': 'Gecko iteratively refines synthetic queries via retrieval, re-ranking, relabeling', 'importance': 'okay', 'assignment': 'support'}, {'text': 'TPPO targets interactive query suggestion, not offline document-based generation', 'importance': 'okay', 'assignment': 'support'}]","{'strict_vital_score': 0.7142857142857143, 'strict_all_score': 0.8461538461538461, 'vital_score': 0.7142857142857143, 'all_score': 0.8461538461538461}"
