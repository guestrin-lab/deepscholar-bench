qid,query,nuggets,supported_nuggets,partially_supported_nuggets,nuggets_metrics
2506.00434v1,"Write a Related Works section for an academic paper given the paper's abstract. Here is the paper abstract:
In this paper, we address the crucial task of brain tumor segmentation in
medical imaging and propose innovative approaches to enhance its performance.
The current state-of-the-art nnU-Net has shown promising results but suffers
from extensive training requirements and underutilization of pre-trained
weights. To overcome these limitations, we integrate Axial-Coronal-Sagittal
convolutions and pre-trained weights from ImageNet into the nnU-Net framework,
resulting in reduced training epochs, reduced trainable parameters, and
improved efficiency. Two strategies for transferring 2D pre-trained weights to
the 3D domain are presented, ensuring the preservation of learned relationships
and feature representations critical for effective information propagation.
Furthermore, we explore a joint classification and segmentation model that
leverages pre-trained encoders from a brain glioma grade classification proxy
task, leading to enhanced segmentation performance, especially for challenging
tumor labels. Experimental results demonstrate that our proposed methods in the
fast training settings achieve comparable or even outperform the ensemble of
cross-validation models, a common practice in the brain tumor segmentation
literature.","[{'text': 'U-Net is the standard for medical image segmentation', 'importance': 'vital', 'assignment': 'support'}, {'text': 'nnU-Net automates configuration and dominates BraTS challenges', 'importance': 'vital', 'assignment': 'support'}, {'text': 'Cross-validation ensembles are common but computationally expensive', 'importance': 'vital', 'assignment': 'support'}, {'text': 'Transfer learning is gaining attention for efficiency in segmentation', 'importance': 'vital', 'assignment': 'support'}, {'text': 'Large-scale 2D pre-trained weights (e.g., ImageNet) are underutilized', 'importance': 'vital', 'assignment': 'support'}, {'text': 'Efficient training and fine-tuning in 3D segmentation remain challenging', 'importance': 'vital', 'assignment': 'support'}, {'text': 'BraTS challenge solutions rely on U-shaped encoder-decoder CNNs', 'importance': 'okay', 'assignment': 'support'}, {'text': 'Transformer-based methods like TransBTS, SwinUNetR show comparable performance', 'importance': 'okay', 'assignment': 'support'}, {'text': 'Med3D provides 3D pre-trained weights but with limited data scale', 'importance': 'okay', 'assignment': 'support'}, {'text': 'Model Genesis uses self-supervised learning on 3D medical images', 'importance': 'okay', 'assignment': 'support'}, {'text': 'Fully-supervised approaches still outperform self-supervised methods', 'importance': 'okay', 'assignment': 'support'}]","[{'text': 'U-Net is the standard for medical image segmentation', 'importance': 'vital', 'assignment': 'support'}, {'text': 'nnU-Net automates configuration and dominates BraTS challenges', 'importance': 'vital', 'assignment': 'support'}, {'text': 'Cross-validation ensembles are common but computationally expensive', 'importance': 'vital', 'assignment': 'support'}, {'text': 'Transfer learning is gaining attention for efficiency in segmentation', 'importance': 'vital', 'assignment': 'support'}, {'text': 'Large-scale 2D pre-trained weights (e.g., ImageNet) are underutilized', 'importance': 'vital', 'assignment': 'support'}, {'text': 'Efficient training and fine-tuning in 3D segmentation remain challenging', 'importance': 'vital', 'assignment': 'support'}, {'text': 'BraTS challenge solutions rely on U-shaped encoder-decoder CNNs', 'importance': 'okay', 'assignment': 'support'}, {'text': 'Transformer-based methods like TransBTS, SwinUNetR show comparable performance', 'importance': 'okay', 'assignment': 'support'}, {'text': 'Med3D provides 3D pre-trained weights but with limited data scale', 'importance': 'okay', 'assignment': 'support'}, {'text': 'Model Genesis uses self-supervised learning on 3D medical images', 'importance': 'okay', 'assignment': 'support'}, {'text': 'Fully-supervised approaches still outperform self-supervised methods', 'importance': 'okay', 'assignment': 'support'}]","[{'text': 'U-Net is the standard for medical image segmentation', 'importance': 'vital', 'assignment': 'support'}, {'text': 'nnU-Net automates configuration and dominates BraTS challenges', 'importance': 'vital', 'assignment': 'support'}, {'text': 'Cross-validation ensembles are common but computationally expensive', 'importance': 'vital', 'assignment': 'support'}, {'text': 'Transfer learning is gaining attention for efficiency in segmentation', 'importance': 'vital', 'assignment': 'support'}, {'text': 'Large-scale 2D pre-trained weights (e.g., ImageNet) are underutilized', 'importance': 'vital', 'assignment': 'support'}, {'text': 'Efficient training and fine-tuning in 3D segmentation remain challenging', 'importance': 'vital', 'assignment': 'support'}, {'text': 'BraTS challenge solutions rely on U-shaped encoder-decoder CNNs', 'importance': 'okay', 'assignment': 'support'}, {'text': 'Transformer-based methods like TransBTS, SwinUNetR show comparable performance', 'importance': 'okay', 'assignment': 'support'}, {'text': 'Med3D provides 3D pre-trained weights but with limited data scale', 'importance': 'okay', 'assignment': 'support'}, {'text': 'Model Genesis uses self-supervised learning on 3D medical images', 'importance': 'okay', 'assignment': 'support'}, {'text': 'Fully-supervised approaches still outperform self-supervised methods', 'importance': 'okay', 'assignment': 'support'}]","{'strict_vital_score': 1.0, 'strict_all_score': 1.0, 'vital_score': 1.0, 'all_score': 1.0}"
