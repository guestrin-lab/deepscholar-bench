{
  "qid": "2505.24575v1",
  "query": "Write a Related Works section for an academic paper given the paper's abstract. Here is the paper abstract:\nSummarizing long-form narratives--such as books, movies, and TV\nscripts--requires capturing intricate plotlines, character interactions, and\nthematic coherence, a task that remains challenging for existing LLMs. We\nintroduce NexusSum, a multi-agent LLM framework for narrative summarization\nthat processes long-form text through a structured, sequential\npipeline--without requiring fine-tuning. Our approach introduces two key\ninnovations: (1) Dialogue-to-Description Transformation: A narrative-specific\npreprocessing method that standardizes character dialogue and descriptive text\ninto a unified format, improving coherence. (2) Hierarchical Multi-LLM\nSummarization: A structured summarization pipeline that optimizes chunk\nprocessing and controls output length for accurate, high-quality summaries. Our\nmethod establishes a new state-of-the-art in narrative summarization, achieving\nup to a 30.0% improvement in BERTScore (F1) across books, movies, and TV\nscripts. These results demonstrate the effectiveness of multi-agent LLMs in\nhandling long-form content, offering a scalable approach for structured\nsummarization in diverse storytelling domains.",
  "nuggets": [
    {
      "text": "Narrative summarization requires handling complex plots and character arcs",
      "importance": "vital",
      "assignment": "support"
    },
    {
      "text": "Extractive-abstractive pipelines risk losing narrative coherence and event dependencies",
      "importance": "vital",
      "assignment": "support"
    },
    {
      "text": "Prior methods struggle with full text processing and truncate key content",
      "importance": "vital",
      "assignment": "support"
    },
    {
      "text": "Dialogue-to-description transformation enables holistic, coherent narrative processing",
      "importance": "vital",
      "assignment": "support"
    },
    {
      "text": "Transformer models face scalability issues with long-context summarization",
      "importance": "vital",
      "assignment": "support"
    },
    {
      "text": "Chunking-based methods segment text for hierarchical summarization",
      "importance": "vital",
      "assignment": "support"
    },
    {
      "text": "Existing multi-agent LLMs lack narrative-specific adaptations for coherence and character interactions",
      "importance": "vital",
      "assignment": "support"
    },
    {
      "text": "NexusSum offers a training-free, multi-agent LLM approach for full text summarization",
      "importance": "vital",
      "assignment": "support"
    },
    {
      "text": "NexusSum integrates dialogue-to-description transformation and systematic length control",
      "importance": "vital",
      "assignment": "support"
    },
    {
      "text": "NexusSum achieves up to 30% BERTScore (F1) improvement on books, movies, TV scripts",
      "importance": "vital",
      "assignment": "not_support"
    },
    {
      "text": "NexusSum ensures coherent, contextually faithful summaries for long-form storytelling",
      "importance": "vital",
      "assignment": "support"
    },
    {
      "text": "BookSum, MENSA, MovieSum, SummScreenFD are key narrative summarization datasets",
      "importance": "okay",
      "assignment": "support"
    },
    {
      "text": "Scene-based and discourse-aware models use graphs and saliency classifiers",
      "importance": "okay",
      "assignment": "support"
    },
    {
      "text": "Sparse attention, memory-efficient encoding, and long-context finetuning address scalability",
      "importance": "okay",
      "assignment": "support"
    },
    {
      "text": "Expanded context windows help but degrade in multi-turn dependencies and coherence",
      "importance": "okay",
      "assignment": "support"
    },
    {
      "text": "SLED and Unlimiformer use chunking for long-form summarization",
      "importance": "okay",
      "assignment": "support"
    },
    {
      "text": "CachED improves efficiency via gradient caching but requires finetuning",
      "importance": "okay",
      "assignment": "support"
    },
    {
      "text": "Multi-agent LLM frameworks like CoA and BooookScore use hierarchical merging and refinement",
      "importance": "okay",
      "assignment": "support"
    },
    {
      "text": "Retrieval-augmented generation improves factuality but misses thematic continuity in narratives",
      "importance": "okay",
      "assignment": "support"
    }
  ],
  "supported_nuggets": [
    {
      "text": "Narrative summarization requires handling complex plots and character arcs",
      "importance": "vital",
      "assignment": "support"
    },
    {
      "text": "Extractive-abstractive pipelines risk losing narrative coherence and event dependencies",
      "importance": "vital",
      "assignment": "support"
    },
    {
      "text": "Prior methods struggle with full text processing and truncate key content",
      "importance": "vital",
      "assignment": "support"
    },
    {
      "text": "Dialogue-to-description transformation enables holistic, coherent narrative processing",
      "importance": "vital",
      "assignment": "support"
    },
    {
      "text": "Transformer models face scalability issues with long-context summarization",
      "importance": "vital",
      "assignment": "support"
    },
    {
      "text": "Chunking-based methods segment text for hierarchical summarization",
      "importance": "vital",
      "assignment": "support"
    },
    {
      "text": "Existing multi-agent LLMs lack narrative-specific adaptations for coherence and character interactions",
      "importance": "vital",
      "assignment": "support"
    },
    {
      "text": "NexusSum offers a training-free, multi-agent LLM approach for full text summarization",
      "importance": "vital",
      "assignment": "support"
    },
    {
      "text": "NexusSum integrates dialogue-to-description transformation and systematic length control",
      "importance": "vital",
      "assignment": "support"
    },
    {
      "text": "NexusSum ensures coherent, contextually faithful summaries for long-form storytelling",
      "importance": "vital",
      "assignment": "support"
    },
    {
      "text": "BookSum, MENSA, MovieSum, SummScreenFD are key narrative summarization datasets",
      "importance": "okay",
      "assignment": "support"
    },
    {
      "text": "Scene-based and discourse-aware models use graphs and saliency classifiers",
      "importance": "okay",
      "assignment": "support"
    },
    {
      "text": "Sparse attention, memory-efficient encoding, and long-context finetuning address scalability",
      "importance": "okay",
      "assignment": "support"
    },
    {
      "text": "Expanded context windows help but degrade in multi-turn dependencies and coherence",
      "importance": "okay",
      "assignment": "support"
    },
    {
      "text": "SLED and Unlimiformer use chunking for long-form summarization",
      "importance": "okay",
      "assignment": "support"
    },
    {
      "text": "CachED improves efficiency via gradient caching but requires finetuning",
      "importance": "okay",
      "assignment": "support"
    },
    {
      "text": "Multi-agent LLM frameworks like CoA and BooookScore use hierarchical merging and refinement",
      "importance": "okay",
      "assignment": "support"
    },
    {
      "text": "Retrieval-augmented generation improves factuality but misses thematic continuity in narratives",
      "importance": "okay",
      "assignment": "support"
    }
  ],
  "partially_supported_nuggets": [
    {
      "text": "Narrative summarization requires handling complex plots and character arcs",
      "importance": "vital",
      "assignment": "support"
    },
    {
      "text": "Extractive-abstractive pipelines risk losing narrative coherence and event dependencies",
      "importance": "vital",
      "assignment": "support"
    },
    {
      "text": "Prior methods struggle with full text processing and truncate key content",
      "importance": "vital",
      "assignment": "support"
    },
    {
      "text": "Dialogue-to-description transformation enables holistic, coherent narrative processing",
      "importance": "vital",
      "assignment": "support"
    },
    {
      "text": "Transformer models face scalability issues with long-context summarization",
      "importance": "vital",
      "assignment": "support"
    },
    {
      "text": "Chunking-based methods segment text for hierarchical summarization",
      "importance": "vital",
      "assignment": "support"
    },
    {
      "text": "Existing multi-agent LLMs lack narrative-specific adaptations for coherence and character interactions",
      "importance": "vital",
      "assignment": "support"
    },
    {
      "text": "NexusSum offers a training-free, multi-agent LLM approach for full text summarization",
      "importance": "vital",
      "assignment": "support"
    },
    {
      "text": "NexusSum integrates dialogue-to-description transformation and systematic length control",
      "importance": "vital",
      "assignment": "support"
    },
    {
      "text": "NexusSum ensures coherent, contextually faithful summaries for long-form storytelling",
      "importance": "vital",
      "assignment": "support"
    },
    {
      "text": "BookSum, MENSA, MovieSum, SummScreenFD are key narrative summarization datasets",
      "importance": "okay",
      "assignment": "support"
    },
    {
      "text": "Scene-based and discourse-aware models use graphs and saliency classifiers",
      "importance": "okay",
      "assignment": "support"
    },
    {
      "text": "Sparse attention, memory-efficient encoding, and long-context finetuning address scalability",
      "importance": "okay",
      "assignment": "support"
    },
    {
      "text": "Expanded context windows help but degrade in multi-turn dependencies and coherence",
      "importance": "okay",
      "assignment": "support"
    },
    {
      "text": "SLED and Unlimiformer use chunking for long-form summarization",
      "importance": "okay",
      "assignment": "support"
    },
    {
      "text": "CachED improves efficiency via gradient caching but requires finetuning",
      "importance": "okay",
      "assignment": "support"
    },
    {
      "text": "Multi-agent LLM frameworks like CoA and BooookScore use hierarchical merging and refinement",
      "importance": "okay",
      "assignment": "support"
    },
    {
      "text": "Retrieval-augmented generation improves factuality but misses thematic continuity in narratives",
      "importance": "okay",
      "assignment": "support"
    }
  ],
  "nuggets_metrics": {
    "strict_vital_score": 0.9090909090909091,
    "strict_all_score": 0.9473684210526315,
    "vital_score": 0.9090909090909091,
    "all_score": 0.9473684210526315
  }
}