{
  "qid": "2506.01037v1",
  "query": "Write a Related Works section for an academic paper given the paper's abstract. Here is the paper abstract:\nExisting diffusion-based video super-resolution (VSR) methods are susceptible\nto introducing complex degradations and noticeable artifacts into\nhigh-resolution videos due to their inherent randomness. In this paper, we\npropose a noise-robust real-world VSR framework by incorporating\nself-supervised learning and Mamba into pre-trained latent diffusion models. To\nensure content consistency across adjacent frames, we enhance the diffusion\nmodel with a global spatio-temporal attention mechanism using the Video\nState-Space block with a 3D Selective Scan module, which reinforces coherence\nat an affordable computational cost. To further reduce artifacts in generated\ndetails, we introduce a self-supervised ControlNet that leverages HR features\nas guidance and employs contrastive learning to extract degradation-insensitive\nfeatures from LR videos. Finally, a three-stage training strategy based on a\nmixture of HR-LR videos is proposed to stabilize VSR training. The proposed\nSelf-supervised ControlNet with Spatio-Temporal Continuous Mamba based VSR\nalgorithm achieves superior perceptual quality than state-of-the-arts on\nreal-world VSR benchmark datasets, validating the effectiveness of the proposed\nmodel design and training strategies.",
  "nuggets": [
    {
      "text": "Most VSR assumes pre-defined degradation, struggles with real-world degradations",
      "importance": "vital",
      "assignment": "support"
    },
    {
      "text": "Maintaining temporal consistency and photorealism in VSR is challenging",
      "importance": "vital",
      "assignment": "support"
    },
    {
      "text": "Diffusion-based VSR can introduce artifacts due to randomness",
      "importance": "vital",
      "assignment": "not_support"
    },
    {
      "text": "Mamba: adaptive state-space model, context-dependent reasoning",
      "importance": "vital",
      "assignment": "support"
    },
    {
      "text": "Mamba's application to VSR is unexplored",
      "importance": "vital",
      "assignment": "support"
    },
    {
      "text": "ControlNet leverages HR features and contrastive learning for artifact reduction",
      "importance": "vital",
      "assignment": "not_support"
    },
    {
      "text": "Video super-resolution (VSR) enhances HR videos from degraded LR inputs",
      "importance": "okay",
      "assignment": "support"
    },
    {
      "text": "VSR methods: temporal sliding-window and recurrent frameworks",
      "importance": "okay",
      "assignment": "support"
    },
    {
      "text": "Sliding-window VSR uses fixed neighboring frames, limited temporal context",
      "importance": "okay",
      "assignment": "support"
    },
    {
      "text": "Recurrent VSR exploits longer temporal dependencies via RNNs",
      "importance": "okay",
      "assignment": "support"
    },
    {
      "text": "Real-world VSR data collection is labor-intensive, limited generalization",
      "importance": "okay",
      "assignment": "support"
    },
    {
      "text": "Data augmentation with diverse degradations improves VSR robustness",
      "importance": "okay",
      "assignment": "partial_support"
    },
    {
      "text": "State space models (S4) capture long-range dependencies in sequences",
      "importance": "okay",
      "assignment": "support"
    },
    {
      "text": "S4's LTI property limits adaptability to dynamic content",
      "importance": "okay",
      "assignment": "support"
    },
    {
      "text": "Self-supervised learning (SSL) excels in computer vision tasks",
      "importance": "okay",
      "assignment": "support"
    },
    {
      "text": "Contrastive learning: prominent SSL method for representation learning",
      "importance": "okay",
      "assignment": "support"
    },
    {
      "text": "Contrastive learning promotes separation of positive and negative examples",
      "importance": "okay",
      "assignment": "support"
    }
  ],
  "supported_nuggets": [
    {
      "text": "Most VSR assumes pre-defined degradation, struggles with real-world degradations",
      "importance": "vital",
      "assignment": "support"
    },
    {
      "text": "Maintaining temporal consistency and photorealism in VSR is challenging",
      "importance": "vital",
      "assignment": "support"
    },
    {
      "text": "Mamba: adaptive state-space model, context-dependent reasoning",
      "importance": "vital",
      "assignment": "support"
    },
    {
      "text": "Mamba's application to VSR is unexplored",
      "importance": "vital",
      "assignment": "support"
    },
    {
      "text": "Video super-resolution (VSR) enhances HR videos from degraded LR inputs",
      "importance": "okay",
      "assignment": "support"
    },
    {
      "text": "VSR methods: temporal sliding-window and recurrent frameworks",
      "importance": "okay",
      "assignment": "support"
    },
    {
      "text": "Sliding-window VSR uses fixed neighboring frames, limited temporal context",
      "importance": "okay",
      "assignment": "support"
    },
    {
      "text": "Recurrent VSR exploits longer temporal dependencies via RNNs",
      "importance": "okay",
      "assignment": "support"
    },
    {
      "text": "Real-world VSR data collection is labor-intensive, limited generalization",
      "importance": "okay",
      "assignment": "support"
    },
    {
      "text": "State space models (S4) capture long-range dependencies in sequences",
      "importance": "okay",
      "assignment": "support"
    },
    {
      "text": "S4's LTI property limits adaptability to dynamic content",
      "importance": "okay",
      "assignment": "support"
    },
    {
      "text": "Self-supervised learning (SSL) excels in computer vision tasks",
      "importance": "okay",
      "assignment": "support"
    },
    {
      "text": "Contrastive learning: prominent SSL method for representation learning",
      "importance": "okay",
      "assignment": "support"
    },
    {
      "text": "Contrastive learning promotes separation of positive and negative examples",
      "importance": "okay",
      "assignment": "support"
    }
  ],
  "partially_supported_nuggets": [
    {
      "text": "Most VSR assumes pre-defined degradation, struggles with real-world degradations",
      "importance": "vital",
      "assignment": "support"
    },
    {
      "text": "Maintaining temporal consistency and photorealism in VSR is challenging",
      "importance": "vital",
      "assignment": "support"
    },
    {
      "text": "Mamba: adaptive state-space model, context-dependent reasoning",
      "importance": "vital",
      "assignment": "support"
    },
    {
      "text": "Mamba's application to VSR is unexplored",
      "importance": "vital",
      "assignment": "support"
    },
    {
      "text": "Video super-resolution (VSR) enhances HR videos from degraded LR inputs",
      "importance": "okay",
      "assignment": "support"
    },
    {
      "text": "VSR methods: temporal sliding-window and recurrent frameworks",
      "importance": "okay",
      "assignment": "support"
    },
    {
      "text": "Sliding-window VSR uses fixed neighboring frames, limited temporal context",
      "importance": "okay",
      "assignment": "support"
    },
    {
      "text": "Recurrent VSR exploits longer temporal dependencies via RNNs",
      "importance": "okay",
      "assignment": "support"
    },
    {
      "text": "Real-world VSR data collection is labor-intensive, limited generalization",
      "importance": "okay",
      "assignment": "support"
    },
    {
      "text": "Data augmentation with diverse degradations improves VSR robustness",
      "importance": "okay",
      "assignment": "partial_support"
    },
    {
      "text": "State space models (S4) capture long-range dependencies in sequences",
      "importance": "okay",
      "assignment": "support"
    },
    {
      "text": "S4's LTI property limits adaptability to dynamic content",
      "importance": "okay",
      "assignment": "support"
    },
    {
      "text": "Self-supervised learning (SSL) excels in computer vision tasks",
      "importance": "okay",
      "assignment": "support"
    },
    {
      "text": "Contrastive learning: prominent SSL method for representation learning",
      "importance": "okay",
      "assignment": "support"
    },
    {
      "text": "Contrastive learning promotes separation of positive and negative examples",
      "importance": "okay",
      "assignment": "support"
    }
  ],
  "nuggets_metrics": {
    "strict_vital_score": 0.6666666666666666,
    "strict_all_score": 0.8235294117647058,
    "vital_score": 0.6666666666666666,
    "all_score": 0.8529411764705882
  }
}