qid,query,nuggets,supported_nuggets,partially_supported_nuggets,nuggets_metrics
2505.19356v1,"Write a Related Works section for an academic paper given the paper's abstract. Here is the paper abstract:
Neural retrieval methods using transformer-based pre-trained language models
have advanced multilingual and cross-lingual retrieval. However, their
effectiveness for low-resource, morphologically rich languages such as Amharic
remains underexplored due to data scarcity and suboptimal tokenization. We
address this gap by introducing Amharic-specific dense retrieval models based
on pre-trained Amharic BERT and RoBERTa backbones. Our proposed
RoBERTa-Base-Amharic-Embed model (110M parameters) achieves a 17.6% relative
improvement in MRR@10 and a 9.86% gain in Recall@10 over the strongest
multilingual baseline, Arctic Embed 2.0 (568M parameters). More compact
variants, such as RoBERTa-Medium-Amharic-Embed (42M), remain competitive while
being over 13x smaller. Additionally, we train a ColBERT-based late interaction
retrieval model that achieves the highest MRR@10 score (0.843) among all
evaluated models. We benchmark our proposed models against both sparse and
dense retrieval baselines to systematically assess retrieval effectiveness in
Amharic. Our analysis highlights key challenges in low-resource settings and
underscores the importance of language-specific adaptation. To foster future
research in low-resource IR, we publicly release our dataset, codebase, and
trained models at https://github.com/kidist-amde/amharic-ir-benchmarks.","[{'text': 'Dense retrieval uses neural encoders for semantic matching via embeddings', 'importance': 'vital', 'assignment': 'support'}, {'text': 'Multilingual models (mBERT, XLM-R, AfriBERTa) partially address data scarcity', 'importance': 'vital', 'assignment': 'support'}, {'text': 'Effectiveness of dense retrieval in Amharic remains underexplored', 'importance': 'vital', 'assignment': 'support'}, {'text': 'Tokenization challenges degrade retrieval in morphologically rich languages like Amharic', 'importance': 'vital', 'assignment': 'support'}, {'text': 'State-of-the-art models (Arctic Embed 2.0, Multilingual E5) struggle with Amharic', 'importance': 'vital', 'assignment': 'support'}, {'text': 'Systematic evaluation of sparse and dense retrieval in Amharic is lacking', 'importance': 'vital', 'assignment': 'support'}, {'text': 'Language-specific adaptation is crucial for low-resource IR', 'importance': 'vital', 'assignment': 'partial_support'}, {'text': 'Recent work introduces Amharic-specific dense and ColBERT retrieval models', 'importance': 'vital', 'assignment': 'support'}, {'text': 'Tokenization errors fragment Amharic representations, harming retrieval', 'importance': 'vital', 'assignment': 'support'}, {'text': 'BM25 is efficient but struggles with morphological variability in Amharic', 'importance': 'okay', 'assignment': 'support'}, {'text': 'LSR methods improve sparse retrieval but need annotated data and morphological tools', 'importance': 'okay', 'assignment': 'support'}, {'text': 'Unsupervised contrastive models (Contriever) show promise but lack Amharic evaluation', 'importance': 'okay', 'assignment': 'support'}, {'text': 'Prior Amharic IR work used pre-trained embeddings and morphological tools', 'importance': 'okay', 'assignment': 'support'}, {'text': '2AIRTC provides Amharic IR test collection but lacks strong baselines', 'importance': 'okay', 'assignment': 'support'}, {'text': 'Amharic Passage Retrieval Dataset enables robust evaluation', 'importance': 'okay', 'assignment': 'support'}, {'text': 'Compact Amharic models achieve competitive performance with fewer parameters', 'importance': 'okay', 'assignment': 'not_support'}]","[{'text': 'Dense retrieval uses neural encoders for semantic matching via embeddings', 'importance': 'vital', 'assignment': 'support'}, {'text': 'Multilingual models (mBERT, XLM-R, AfriBERTa) partially address data scarcity', 'importance': 'vital', 'assignment': 'support'}, {'text': 'Effectiveness of dense retrieval in Amharic remains underexplored', 'importance': 'vital', 'assignment': 'support'}, {'text': 'Tokenization challenges degrade retrieval in morphologically rich languages like Amharic', 'importance': 'vital', 'assignment': 'support'}, {'text': 'State-of-the-art models (Arctic Embed 2.0, Multilingual E5) struggle with Amharic', 'importance': 'vital', 'assignment': 'support'}, {'text': 'Systematic evaluation of sparse and dense retrieval in Amharic is lacking', 'importance': 'vital', 'assignment': 'support'}, {'text': 'Recent work introduces Amharic-specific dense and ColBERT retrieval models', 'importance': 'vital', 'assignment': 'support'}, {'text': 'Tokenization errors fragment Amharic representations, harming retrieval', 'importance': 'vital', 'assignment': 'support'}, {'text': 'BM25 is efficient but struggles with morphological variability in Amharic', 'importance': 'okay', 'assignment': 'support'}, {'text': 'LSR methods improve sparse retrieval but need annotated data and morphological tools', 'importance': 'okay', 'assignment': 'support'}, {'text': 'Unsupervised contrastive models (Contriever) show promise but lack Amharic evaluation', 'importance': 'okay', 'assignment': 'support'}, {'text': 'Prior Amharic IR work used pre-trained embeddings and morphological tools', 'importance': 'okay', 'assignment': 'support'}, {'text': '2AIRTC provides Amharic IR test collection but lacks strong baselines', 'importance': 'okay', 'assignment': 'support'}, {'text': 'Amharic Passage Retrieval Dataset enables robust evaluation', 'importance': 'okay', 'assignment': 'support'}]","[{'text': 'Dense retrieval uses neural encoders for semantic matching via embeddings', 'importance': 'vital', 'assignment': 'support'}, {'text': 'Multilingual models (mBERT, XLM-R, AfriBERTa) partially address data scarcity', 'importance': 'vital', 'assignment': 'support'}, {'text': 'Effectiveness of dense retrieval in Amharic remains underexplored', 'importance': 'vital', 'assignment': 'support'}, {'text': 'Tokenization challenges degrade retrieval in morphologically rich languages like Amharic', 'importance': 'vital', 'assignment': 'support'}, {'text': 'State-of-the-art models (Arctic Embed 2.0, Multilingual E5) struggle with Amharic', 'importance': 'vital', 'assignment': 'support'}, {'text': 'Systematic evaluation of sparse and dense retrieval in Amharic is lacking', 'importance': 'vital', 'assignment': 'support'}, {'text': 'Language-specific adaptation is crucial for low-resource IR', 'importance': 'vital', 'assignment': 'partial_support'}, {'text': 'Recent work introduces Amharic-specific dense and ColBERT retrieval models', 'importance': 'vital', 'assignment': 'support'}, {'text': 'Tokenization errors fragment Amharic representations, harming retrieval', 'importance': 'vital', 'assignment': 'support'}, {'text': 'BM25 is efficient but struggles with morphological variability in Amharic', 'importance': 'okay', 'assignment': 'support'}, {'text': 'LSR methods improve sparse retrieval but need annotated data and morphological tools', 'importance': 'okay', 'assignment': 'support'}, {'text': 'Unsupervised contrastive models (Contriever) show promise but lack Amharic evaluation', 'importance': 'okay', 'assignment': 'support'}, {'text': 'Prior Amharic IR work used pre-trained embeddings and morphological tools', 'importance': 'okay', 'assignment': 'support'}, {'text': '2AIRTC provides Amharic IR test collection but lacks strong baselines', 'importance': 'okay', 'assignment': 'support'}, {'text': 'Amharic Passage Retrieval Dataset enables robust evaluation', 'importance': 'okay', 'assignment': 'support'}]","{'strict_vital_score': 0.8888888888888888, 'strict_all_score': 0.875, 'vital_score': 0.9444444444444444, 'all_score': 0.90625}"
