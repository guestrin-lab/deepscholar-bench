qid,query,nuggets,supported_nuggets,partially_supported_nuggets,nuggets_metrics
2506.00333v1,"Write a Related Works section for an academic paper given the paper's abstract. Here is the paper abstract:
Open-vocabulary object detection models allow users to freely specify a class
vocabulary in natural language at test time, guiding the detection of desired
objects. However, vocabularies can be overly broad or even mis-specified,
hampering the overall performance of the detector. In this work, we propose a
plug-and-play Vocabulary Adapter (VocAda) to refine the user-defined
vocabulary, automatically tailoring it to categories that are relevant for a
given image. VocAda does not require any training, it operates at inference
time in three steps: i) it uses an image captionner to describe visible
objects, ii) it parses nouns from those captions, and iii) it selects relevant
classes from the user-defined vocabulary, discarding irrelevant ones.
Experiments on COCO and Objects365 with three state-of-the-art detectors show
that VocAda consistently improves performance, proving its versatility. The
code is open source.","[{'text': 'Open-vocabulary object detection maps regions to vision-language embedding spaces', 'importance': 'vital', 'assignment': 'support'}, {'text': 'CLIP and similar models provide frozen embedding spaces for OVOD', 'importance': 'vital', 'assignment': 'support'}, {'text': 'OVOD detectors train on box-labeled data with limited categories', 'importance': 'vital', 'assignment': 'support'}, {'text': 'Most prior work focuses on training-time improvements', 'importance': 'vital', 'assignment': 'support'}, {'text': 'SHiNe augments vocabularies via prompt engineering and semantic hierarchies', 'importance': 'vital', 'assignment': 'support'}, {'text': 'VocAda adapts the vocabulary per image at test time', 'importance': 'vital', 'assignment': 'support'}, {'text': 'VocAda operates at inference, not requiring training or fine-tuning', 'importance': 'vital', 'assignment': 'partial_support'}, {'text': 'VocAda uses image captioning and noun parsing to refine vocabularies', 'importance': 'vital', 'assignment': 'not_support'}, {'text': 'VocAda discards irrelevant user-specified classes per image', 'importance': 'vital', 'assignment': 'partial_support'}, {'text': 'VocAda improves off-the-shelf OVOD detectors without fine-tuning', 'importance': 'vital', 'assignment': 'support'}, {'text': 'Image-level annotated datasets expand class coverage for OVOD', 'importance': 'okay', 'assignment': 'support'}, {'text': 'Pseudo-labeling improves alignment training in OVOD', 'importance': 'okay', 'assignment': 'support'}, {'text': 'Transfer learning enhances OVOD performance', 'importance': 'okay', 'assignment': 'support'}, {'text': 'Weak supervision methods boost OVOD training', 'importance': 'okay', 'assignment': 'support'}, {'text': 'SHiNe produces a single improved vocabulary for all images', 'importance': 'okay', 'assignment': 'support'}, {'text': ""Prompt engineering can further augment VocAda's refined vocabulary"", 'importance': 'okay', 'assignment': 'support'}]","[{'text': 'Open-vocabulary object detection maps regions to vision-language embedding spaces', 'importance': 'vital', 'assignment': 'support'}, {'text': 'CLIP and similar models provide frozen embedding spaces for OVOD', 'importance': 'vital', 'assignment': 'support'}, {'text': 'OVOD detectors train on box-labeled data with limited categories', 'importance': 'vital', 'assignment': 'support'}, {'text': 'Most prior work focuses on training-time improvements', 'importance': 'vital', 'assignment': 'support'}, {'text': 'SHiNe augments vocabularies via prompt engineering and semantic hierarchies', 'importance': 'vital', 'assignment': 'support'}, {'text': 'VocAda adapts the vocabulary per image at test time', 'importance': 'vital', 'assignment': 'support'}, {'text': 'VocAda improves off-the-shelf OVOD detectors without fine-tuning', 'importance': 'vital', 'assignment': 'support'}, {'text': 'Image-level annotated datasets expand class coverage for OVOD', 'importance': 'okay', 'assignment': 'support'}, {'text': 'Pseudo-labeling improves alignment training in OVOD', 'importance': 'okay', 'assignment': 'support'}, {'text': 'Transfer learning enhances OVOD performance', 'importance': 'okay', 'assignment': 'support'}, {'text': 'Weak supervision methods boost OVOD training', 'importance': 'okay', 'assignment': 'support'}, {'text': 'SHiNe produces a single improved vocabulary for all images', 'importance': 'okay', 'assignment': 'support'}, {'text': ""Prompt engineering can further augment VocAda's refined vocabulary"", 'importance': 'okay', 'assignment': 'support'}]","[{'text': 'Open-vocabulary object detection maps regions to vision-language embedding spaces', 'importance': 'vital', 'assignment': 'support'}, {'text': 'CLIP and similar models provide frozen embedding spaces for OVOD', 'importance': 'vital', 'assignment': 'support'}, {'text': 'OVOD detectors train on box-labeled data with limited categories', 'importance': 'vital', 'assignment': 'support'}, {'text': 'Most prior work focuses on training-time improvements', 'importance': 'vital', 'assignment': 'support'}, {'text': 'SHiNe augments vocabularies via prompt engineering and semantic hierarchies', 'importance': 'vital', 'assignment': 'support'}, {'text': 'VocAda adapts the vocabulary per image at test time', 'importance': 'vital', 'assignment': 'support'}, {'text': 'VocAda operates at inference, not requiring training or fine-tuning', 'importance': 'vital', 'assignment': 'partial_support'}, {'text': 'VocAda discards irrelevant user-specified classes per image', 'importance': 'vital', 'assignment': 'partial_support'}, {'text': 'VocAda improves off-the-shelf OVOD detectors without fine-tuning', 'importance': 'vital', 'assignment': 'support'}, {'text': 'Image-level annotated datasets expand class coverage for OVOD', 'importance': 'okay', 'assignment': 'support'}, {'text': 'Pseudo-labeling improves alignment training in OVOD', 'importance': 'okay', 'assignment': 'support'}, {'text': 'Transfer learning enhances OVOD performance', 'importance': 'okay', 'assignment': 'support'}, {'text': 'Weak supervision methods boost OVOD training', 'importance': 'okay', 'assignment': 'support'}, {'text': 'SHiNe produces a single improved vocabulary for all images', 'importance': 'okay', 'assignment': 'support'}, {'text': ""Prompt engineering can further augment VocAda's refined vocabulary"", 'importance': 'okay', 'assignment': 'support'}]","{'strict_vital_score': 0.7, 'strict_all_score': 0.8125, 'vital_score': 0.8, 'all_score': 0.875}"
