qid,query,nuggets,supported_nuggets,partially_supported_nuggets,nuggets_metrics
2505.12791v1,"Write a Related Works section for an academic paper given the paper's abstract. Here is the paper abstract:
This paper reports on findings from a comparative study on the effectiveness
and efficiency of federated unlearning strategies within Federated Online
Learning to Rank (FOLTR), with specific attention to systematically analysing
the unlearning capabilities of methods in a verifiable manner.
  Federated approaches to ranking of search results have recently garnered
attention to address users privacy concerns. In FOLTR, privacy is safeguarded
by collaboratively training ranking models across decentralized data sources,
preserving individual user data while optimizing search results based on
implicit feedback, such as clicks.
  Recent legislation introduced across numerous countries is establishing the
so called ""the right to be forgotten"", according to which services based on
machine learning models like those in FOLTR should provide capabilities that
allow users to remove their own data from those used to train models. This has
sparked the development of unlearning methods, along with evaluation practices
to measure whether unlearning of a user data successfully occurred. Current
evaluation practices are however often controversial, necessitating the use of
multiple metrics for a more comprehensive assessment -- but previous proposals
of unlearning methods only used single evaluation metrics.
  This paper addresses this limitation: our study rigorously assesses the
effectiveness of unlearning strategies in managing both under-unlearning and
over-unlearning scenarios using adapted, and newly proposed evaluation metrics.
Thanks to our detailed analysis, we uncover the strengths and limitations of
five unlearning strategies, offering valuable insights into optimizing
federated unlearning to balance data privacy and system performance within
FOLTR. We publicly release our code and complete results at
https://github.com/Iris1026/Unlearning-for-FOLTR.git.","[{'text': 'Federated Online Learning to Rank (FOLTR) enables privacy-preserving collaborative ranking', 'importance': 'vital', 'assignment': 'support'}, {'text': 'FOLTR trains ranking models across decentralized data using implicit feedback', 'importance': 'vital', 'assignment': 'support'}, {'text': 'Federated Unlearning (FU) removes individual client data from global models', 'importance': 'vital', 'assignment': 'support'}, {'text': 'FU in FOLTR is largely unexplored; Wang et al. (2024) is the only prior work', 'importance': 'vital', 'assignment': 'support'}, {'text': 'Existing FU methods in FOLTR use limited evaluation metrics', 'importance': 'vital', 'assignment': 'not_support'}, {'text': 'Comprehensive FU evaluation in FOLTR requires multiple metrics for assessment', 'importance': 'vital', 'assignment': 'partial_support'}, {'text': 'FOLtR-ES introduced evolution strategies and local differential privacy to FOLTR', 'importance': 'okay', 'assignment': 'support'}, {'text': 'FOLtR-ES is less effective on large-scale datasets', 'importance': 'okay', 'assignment': 'support'}, {'text': 'FPDGD integrates Pairwise Differentiable Gradient Descent into FOLTR for improved performance', 'importance': 'okay', 'assignment': 'support'}, {'text': 'FPDGD shows strong ranking performance and robustness to data noise', 'importance': 'okay', 'assignment': 'partial_support'}, {'text': 'FOLTR research is early-stage, with foundational studies on privacy and performance', 'importance': 'okay', 'assignment': 'support'}, {'text': 'Naive FU retrains models from scratch, incurring high computational cost', 'importance': 'okay', 'assignment': 'support'}, {'text': 'FedEraser reconstructs unlearned models by adjusting historical client updates', 'importance': 'okay', 'assignment': 'support'}, {'text': 'Other efficient FU methods use knowledge distillation or optimization techniques', 'importance': 'okay', 'assignment': 'support'}, {'text': 'FU has been studied in NLP, recommendation, and knowledge graph domains', 'importance': 'okay', 'assignment': 'partial_support'}, {'text': 'Wang et al. (2024) evaluated FU in FOLTR using user simulation and poisoning attacks', 'importance': 'okay', 'assignment': 'support'}]","[{'text': 'Federated Online Learning to Rank (FOLTR) enables privacy-preserving collaborative ranking', 'importance': 'vital', 'assignment': 'support'}, {'text': 'FOLTR trains ranking models across decentralized data using implicit feedback', 'importance': 'vital', 'assignment': 'support'}, {'text': 'Federated Unlearning (FU) removes individual client data from global models', 'importance': 'vital', 'assignment': 'support'}, {'text': 'FU in FOLTR is largely unexplored; Wang et al. (2024) is the only prior work', 'importance': 'vital', 'assignment': 'support'}, {'text': 'FOLtR-ES introduced evolution strategies and local differential privacy to FOLTR', 'importance': 'okay', 'assignment': 'support'}, {'text': 'FOLtR-ES is less effective on large-scale datasets', 'importance': 'okay', 'assignment': 'support'}, {'text': 'FPDGD integrates Pairwise Differentiable Gradient Descent into FOLTR for improved performance', 'importance': 'okay', 'assignment': 'support'}, {'text': 'FOLTR research is early-stage, with foundational studies on privacy and performance', 'importance': 'okay', 'assignment': 'support'}, {'text': 'Naive FU retrains models from scratch, incurring high computational cost', 'importance': 'okay', 'assignment': 'support'}, {'text': 'FedEraser reconstructs unlearned models by adjusting historical client updates', 'importance': 'okay', 'assignment': 'support'}, {'text': 'Other efficient FU methods use knowledge distillation or optimization techniques', 'importance': 'okay', 'assignment': 'support'}, {'text': 'Wang et al. (2024) evaluated FU in FOLTR using user simulation and poisoning attacks', 'importance': 'okay', 'assignment': 'support'}]","[{'text': 'Federated Online Learning to Rank (FOLTR) enables privacy-preserving collaborative ranking', 'importance': 'vital', 'assignment': 'support'}, {'text': 'FOLTR trains ranking models across decentralized data using implicit feedback', 'importance': 'vital', 'assignment': 'support'}, {'text': 'Federated Unlearning (FU) removes individual client data from global models', 'importance': 'vital', 'assignment': 'support'}, {'text': 'FU in FOLTR is largely unexplored; Wang et al. (2024) is the only prior work', 'importance': 'vital', 'assignment': 'support'}, {'text': 'Comprehensive FU evaluation in FOLTR requires multiple metrics for assessment', 'importance': 'vital', 'assignment': 'partial_support'}, {'text': 'FOLtR-ES introduced evolution strategies and local differential privacy to FOLTR', 'importance': 'okay', 'assignment': 'support'}, {'text': 'FOLtR-ES is less effective on large-scale datasets', 'importance': 'okay', 'assignment': 'support'}, {'text': 'FPDGD integrates Pairwise Differentiable Gradient Descent into FOLTR for improved performance', 'importance': 'okay', 'assignment': 'support'}, {'text': 'FPDGD shows strong ranking performance and robustness to data noise', 'importance': 'okay', 'assignment': 'partial_support'}, {'text': 'FOLTR research is early-stage, with foundational studies on privacy and performance', 'importance': 'okay', 'assignment': 'support'}, {'text': 'Naive FU retrains models from scratch, incurring high computational cost', 'importance': 'okay', 'assignment': 'support'}, {'text': 'FedEraser reconstructs unlearned models by adjusting historical client updates', 'importance': 'okay', 'assignment': 'support'}, {'text': 'Other efficient FU methods use knowledge distillation or optimization techniques', 'importance': 'okay', 'assignment': 'support'}, {'text': 'FU has been studied in NLP, recommendation, and knowledge graph domains', 'importance': 'okay', 'assignment': 'partial_support'}, {'text': 'Wang et al. (2024) evaluated FU in FOLTR using user simulation and poisoning attacks', 'importance': 'okay', 'assignment': 'support'}]","{'strict_vital_score': 0.6666666666666666, 'strict_all_score': 0.75, 'vital_score': 0.75, 'all_score': 0.84375}"
