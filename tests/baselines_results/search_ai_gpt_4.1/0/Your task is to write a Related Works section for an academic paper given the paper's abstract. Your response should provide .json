{
    "latency": 44.676300287246704,
    "output": "Related Works\n\nThe challenge of designing effective tax policy that balances both equity and economic efficiency traces back to the classical optimal income taxation frameworks established in economic literature. The foundational models, such as those of Mirrlees and Saez, have undergone significant refinement. Recent developments propose incorporating utility variance and analogies with portfolio optimization for transparent, progressive optimal taxation [4]. Analytic extensions have examined the welfare-maximizing properties of flat taxes on labor, capital, and consumption, particularly under uncertain investment returns, as exemplified by studies on the Domar-Musgrave effect [1]. Meanwhile, multidimensional approaches further generalize optimal policy analyses, taking into account heterogeneity in skills and behaviors to derive global optimal tax formulas [14].\n\nWealth inequality and the effect of taxation have been a focal point within the modeling literature. Ordinary differential equation (ODE) and kinetic models demonstrate that neither income nor capital gains taxation alone suffices to curb wealth concentration unless set above critical thresholds, drawing implications for wealth tax design and redistribution strategies [10][22]. Similarly, research has identified the parameters necessary for both achieving growth-optimal tax rates and addressing persistent inequality, with stylized models elucidating the sectorial trade-offs inherent to these decisions [20].\n\nOn the computational side, recent years have witnessed the advent of large language models (LLMs) and agent-based modeling (ABM) in economic policy design. The AI Economist framework, which uses two-level deep reinforcement learning, allows both agents and a social planner to co-adapt their behaviors, producing improved policy outcomes in simulated tax environments [1]. Further, frameworks leveraging multiple LLMs as heterogeneous agents simulate the effects of interventions such as interest-income taxation, harnessing the reasoning capabilities of LLMs for nuanced policy evaluation [2]. Agent-based simulations combining LLMs and reinforcement learning have also been applied to examine taxpayer compliance, the endogenous emergence of tax evasion, and the impacts of enforcement and public goods provision [3]. Other works have explored the feasibility of using LLMs in financial markets as trading agents, highlighting the potential of such systems to model economic dynamics relevant to regulatory and fiscal policy [4]. Additionally, there is growing interest in LLM-driven agentic workflows for empirical economic analysis and policy evaluation, often integrating human oversight to ensure interpretability and accountability [5].\n\nThe intersection of agent-based models, LLMs, and optimal taxation is consequently an emerging and promising research area. This literature review highlights the limitations of traditional analytic approaches in addressing heterogeneity and behavioral complexity, while demonstrating how AI-driven methods\u2014particularly those involving LLMs and ABMs\u2014can offer data-driven, adaptive, and scalable solutions for fiscal policy. The proposed TaxAgent, which merges these paradigms, builds directly on these theoretical and computational advancements, and represents a substantial contribution to ongoing efforts in taxation and policy optimization.\n\nReferences\n\n[1] Optimal taxation and the Domar-Musgrave effect (2023) http://arxiv.org/abs/2311.05822v2\n[2] A Multi-LLM-Agent-Based Framework for Economic and Public Policy Analysis (2025) http://arxiv.org/abs/2502.16879v1\n[3] Investigating Tax Evasion Emergence Using Dual Large Language Model and Deep Reinforcement Learning Powered Agent-based Simulation (2025) http://arxiv.org/abs/2501.18177v1\n[4] A new approach to the theory of optimal income tax (2024) http://arxiv.org/abs/2408.14476v1\n[5] Agentic Workflows for Economic Research: Design and Implementation (2025) http://arxiv.org/abs/2504.09736v1\n[10] ODE models of wealth concentration and taxation (2023) http://arxiv.org/abs/2308.01500v1\n[14] Bunching and Taxing Multidimensional Skills (2022) http://arxiv.org/abs/2204.13481v2\n[20] On growth-optimal tax rates and the issue of wealth inequalities (2015) http://arxiv.org/abs/1508.00275v2\n[22] Kinetic models for optimal control of wealth inequalities (2018) http://arxiv.org/abs/1803.02171v2",
    "ctxs": [
        {
            "title": "Optimal taxation and the Domar-Musgrave effect",
            "text": "This article concerns the optimal choice of flat taxes on labor and capital\nincome, and on consumption, in a tractable economic model in which agents are\nsubject to idiosyncratic investment risk. We identify the tax rates which\nmaximize welfare in stationary equilibrium while preserving tax revenue,\nfinding that an increase in welfare equivalent to a permanent increase in\nconsumption of nearly 7% can be achieved by only taxing capital income and\nconsumption. The Domar-Musgrave effect explains cases where it is optimal to\ntax capital income. We characterize the dynamic response to the substitution of\nconsumption taxation for labor income taxation.",
            "url": "http://arxiv.org/abs/2311.05822v2",
            "id": "http://arxiv.org/abs/2311.05822v2",
            "date": "2023-11-10 01:45:46+00:00"
        },
        {
            "title": "Optimal Extraction and Taxation of Strategic Natural Resources: A Differential Game Approach",
            "text": "This paper studies the optimal extraction and taxation of nonrenewable\nnatural resources. It is well known that the market values of the main\nstrategic resources such as oil, natural gas, uranium, copper,..., etc,\nfluctuate randomly following global and seasonal macroeconomic parameters,\nthese values are modeled using Markov switching L\\'evy processes. We formulate\nthis problem as a differential game. The two players of this differential game\nare the mining company whose aim is to maximize the revenues generated from its\nextracting activities and the government agency in charge of regulating and\ntaxing natural resources. We prove the existence of a Nash equilibrium. The\ncorresponding Hamilton Jacobi Isaacs equations are completely solved and the\nvalue functions as well as the optimal extraction and taxation rates are\nderived in closed-form. A Numerical example is presented to illustrate our\nfindings.",
            "url": "http://arxiv.org/abs/1611.02547v2",
            "id": "http://arxiv.org/abs/1611.02547v2",
            "date": "2016-10-27 17:36:27+00:00"
        },
        {
            "title": "Achieving Fairness and Accuracy in Regressive Property Taxation",
            "text": "Regressivity in property taxation, or the disproportionate overassessment of\nlower-valued properties compared to higher-valued ones, results in an unfair\ntaxation burden for Americans living in poverty. To address regressivity and\nenhance both the accuracy and fairness of property assessments, we introduce a\nscalable property valuation model called the $K$-segment model. Our study\nformulates a mathematical framework for the $K$-segment model, which divides a\nsingle model into $K$ segments and employs submodels for each segment.\nSmoothing methods are incorporated to balance and smooth the multiple submodels\nwithin the overall model. To assess the fairness of our proposed model, we\nintroduce two innovative fairness measures for property evaluation and\ntaxation, focusing on group-level fairness and extreme sales price portions\nwhere unfairness typically arises. Compared to the model employed currently in\npractice, our study demonstrates that the $K$-segment model effectively\nimproves fairness based on the proposed measures. Furthermore, we investigate\nthe accuracy--fairness trade-off in property assessments and illustrate how the\n$K$-segment model balances high accuracy with fairness for all properties. Our\nwork uncovers the practical impacts of the $K$-segment models in addressing\nregressivity in property taxation, offering a tangible solution for\npolicymakers and property owners. By implementing this model, we pave the way\nfor a fairer taxation system, ensuring a more equitable distribution of tax\nburdens.",
            "url": "http://arxiv.org/abs/2312.05996v1",
            "id": "http://arxiv.org/abs/2312.05996v1",
            "date": "2023-12-10 21:02:13+00:00"
        },
        {
            "title": "A new approach to the theory of optimal income tax",
            "text": "The Nobel-price winning Mirrlees' theory of optimal taxation inspired a long\nsequence of research on its refinement and enhancement. However, an issue of\nconcern has been always the fact that, as was shown in many publications, the\noptimal schedule in Mirrlees' paradigm of maximising the total utility\n(constructed from individually optimised individual ones) usually did not lead\nto progressive taxation (contradicting the ethically supported practice in\ndeveloped economies), and often even assigned minimal tax rates to the higher\npaid strata of society. The first objective of this paper is to support this\nconclusion by proving a theorem on optimal tax schedule in (practically most\nexploited) piecewise-linear environment under a simplest natural utility\nfunction. The second objective is to suggest a new paradigm for optimal\ntaxation, where instead of just total average utility maximization one\nintroduces a standard deviation of utility as a second parameter (in some\nanalogy with Marcowitz portfolio optimization). We show that this approach\nleads to transparent and easy interpreted optimality criteria for income tax.",
            "url": "http://arxiv.org/abs/2408.14476v1",
            "id": "http://arxiv.org/abs/2408.14476v1",
            "date": "2024-08-10 18:18:31+00:00"
        },
        {
            "title": "Dynamic model of firms competitive interaction on the market with taxation",
            "text": "In this article three models of firms interaction on the market are\ndescribed. One of these models is described by using a differential equation\nand by Lotka-Volterra model, where the equation has a different form. Also,\nthere are models of non-competing and competing firms. The article presents an\nalgorithm for solving the interaction of competing firms in taxation and the\ncalculation of a compromise point. Besides, the article presents a compromise\nbetween the interests of a state and an enterprise.",
            "url": "http://arxiv.org/abs/1905.06364v1",
            "id": "http://arxiv.org/abs/1905.06364v1",
            "date": "2019-05-15 18:13:24+00:00"
        },
        {
            "title": "Climate uncertainty, financial frictions and constrained efficient carbon taxation",
            "text": "In this paper, I consider a simple heterogeneous agents model of a production\neconomy with uncertain climate change and examine constrained efficient carbon\ntaxation. If there are frictionless, complete financial markets, the simple\nmodel predicts a unique Pareto-optimal level of carbon taxes and abatement. In\nthe presence of financial frictions, however, the optimal level of abatement\ncannot be defined without taking a stand on how abatement costs are distributed\namong individuals. I propose a simple linear cost-sharing scheme that has\nseveral desirable normative properties. I use calibrated examples of economies\nwith incomplete financial markets and/or limited market participation to\ndemonstrate that different schemes to share abatement costs can have large\neffects on optimal abatement levels and that the presence of financial\nfrictions can increase optimal abatement by a factor of three relative to the\ncase of frictionless financial market.",
            "url": "http://arxiv.org/abs/2210.09066v1",
            "id": "http://arxiv.org/abs/2210.09066v1",
            "date": "2022-10-17 13:06:08+00:00"
        },
        {
            "title": "Optimal Oil Production and Taxation in Presence of Global Disruptions",
            "text": "This paper studies the optimal extraction policy of an oil field as well as\nthe efficient taxation of the revenues generated. Taking into account the fact\nthat the oil price in worldwide commodity markets fluctuates randomly following\nglobal and seasonal macroeconomic parameters, we model the evolution of the oil\nprice as a mean reverting regime-switching jump diffusion process. Given that\noil producing countries rely on oil sale revenues as well as taxes levied on\noil companies for a good portion of the revenue side of their budgets, we\nformulate this problem as a differential game where the two players are the\nmining company whose aim is to maximize the revenues generated from its\nextracting activities and the government agency in charge of regulating and\ntaxing natural resources. We prove the existence of a Nash equilibrium and the\nconvergence of an approximating scheme for the value functions. Furthermore,\noptimal extraction and fiscal policies that should be applied when the\nequilibrium is reached are derived.A numerical example is presented to\nillustrate these results.",
            "url": "http://arxiv.org/abs/1704.04714v1",
            "id": "http://arxiv.org/abs/1704.04714v1",
            "date": "2017-04-16 03:24:41+00:00"
        },
        {
            "title": "Transfer pricing manipulation, tax penalty cost and the impact of foreign profit taxation",
            "text": "This paper analizes the optimal level of transfer pricing manipulation when\nthe expected tax penalty is a function of the tax enforcement and the market\nprice parameter. The arm's length principle implies the existence of a range of\nacceptable prices shaped by market, and firms can manipulate transfer prices\nmore freely if market price range is wide, or if its delimitations are\ndifficult to determine. Home taxation of foreign profits can reduce income\nshifting incentive, depending on the portion of repatriation for tax purposes.\nWe find that the limited tax credit rule tends to be a less efficient measure,\nnonetheless it is the most widely adopted rule by countries, so to spark the\nperspective of more powerful approaches for taxation of foreign profits.",
            "url": "http://arxiv.org/abs/1508.03853v1",
            "id": "http://arxiv.org/abs/1508.03853v1",
            "date": "2015-08-16 18:11:55+00:00"
        },
        {
            "title": "Recursive Preferences, Correlation Aversion, and the Temporal Resolution of Uncertainty",
            "text": "This paper investigates a novel behavioral feature of recursive preferences:\naversion to risks that persist over time, or simply correlation aversion.\nGreater persistence provides information about future consumption but reduces\nopportunities to hedge consumption risk. I show that, for recursive\npreferences, correlation aversion is equivalent to increasing relative risk\naversion. To quantify correlation aversion, I develop the concept of the\npersistence premium, which measures how much an individual is willing to pay to\neliminate persistence in consumption. I provide an approximation of the\npersistence premium in the spirit of Arrow-Pratt, which provides a quantitative\nrepresentation of the trade-off between information and hedging. I present\nseveral applications. The persistence premium helps create more realistic\ncalibrations for macro-finance models. In an optimal taxation model, I show\nthat recursive preferences unlike standard preferences-lead to more progressive\ntaxation when human capital persistence is greater. Finally, I show that\ncorrelation-averse preferences have a variational representation, linking\ncorrelation aversion to concerns about model misspecification.",
            "url": "http://arxiv.org/abs/2304.04599v5",
            "id": "http://arxiv.org/abs/2304.04599v5",
            "date": "2023-04-10 14:13:44+00:00"
        },
        {
            "title": "ODE models of wealth concentration and taxation",
            "text": "We refer to an individual holding a non-negligible fraction of the country's\ntotal wealth as an oligarch. We explain how a model due to Boghosian et al. can\nbe used to explore the effects of taxation on the emergence of oligarchs. The\nmodel suggests that oligarchs will emerge when wealth taxation is below a\ncertain threshold, not when it is above the threshold. The underlying mechanism\nis a transcritical bifurcation. The model also suggests that taxation of income\nand capital gains alone cannot prevent the emergence of oligarchs. This is an\narticle intended for undergraduate students. We suggest several opportunities\nfor students to explore modifications of the model.",
            "url": "http://arxiv.org/abs/2308.01500v1",
            "id": "http://arxiv.org/abs/2308.01500v1",
            "date": "2023-08-03 01:51:00+00:00"
        },
        {
            "title": "Shrouded Sin Taxes",
            "text": "Strategic shrouding of taxes by profit-maximizing firms can impair the\neffectiveness of corrective taxes. This paper explores tax shrouding and its\nconsequences after the introduction of a digital sin tax designed to discourage\nharmful overconsumption of online sports betting in Germany. In response to the\ntax reform, most firms strategically shroud the tax, i.e., exclude tax\nsurcharges from posted prices. Using an extensive novel panel data set on\nonline betting odds, I causally estimate the effect of the tax on consumer\nbetting prices. Consumers bear, on average, 76% of the tax burden. There is\nconsiderable and long-lasting heterogeneity in effects conditional on shrouding\npractices. Firms that shroud taxes can pass 90% of the tax onto consumers,\nwhile the pass-through rate is 16% for firms that directly post tax-inclusive\nprices. To understand the results' underlying mechanisms and policy\nimplications, I propose an optimal corrective taxation model where\noligopolistic firms compete on base prices and can shroud additive taxes. Tax\nshrouding is only attainable in equilibrium if (some) consumers underreact to\nshrouded attributes. According to the theoretical predictions, the empirically\nidentified heterogeneity suggests that strategic tax shrouding significantly\nattenuates the positive corrective welfare effects of the tax. The results\nprompt regulating shrouding practices in the context of corrective taxation.",
            "url": "http://arxiv.org/abs/2409.01493v1",
            "id": "http://arxiv.org/abs/2409.01493v1",
            "date": "2024-09-02 23:25:12+00:00"
        },
        {
            "title": "Taxation of a GMWB Variable Annuity in a Stochastic Interest Rate Model",
            "text": "Modeling taxation of Variable Annuities has been frequently neglected but\naccounting for it can significantly improve the explanation of the withdrawal\ndynamics and lead to a better modeling of the financial cost of these insurance\nproducts. The importance of including a model for taxation has first been\nobserved by Moenig and Bauer (2016) while considering a GMWB Variable Annuity.\nIn particular, they consider the simple Black-Scholes dynamics to describe the\nunderlying security. Nevertheless, GMWB are long term products and thus\naccounting for stochastic interest rate has relevant effects on both the\nfinancial evaluation and the policy holder behavior, as observed by Gouden\\`ege\net al. (2018). In this paper we investigate the outcomes of these two elements\ntogether on GMWB evaluation. To this aim, we develop a numerical framework\nwhich allows one to efficiently compute the fair value of a policy. Numerical\nresults show that accounting for both taxation and stochastic interest rate has\na determinant impact on the withdrawal strategy and on the cost of GMWB\ncontracts. In addition, it can explain why these products are so popular with\npeople looking for a protected form of investment for retirement.",
            "url": "http://arxiv.org/abs/1901.11296v2",
            "id": "http://arxiv.org/abs/1901.11296v2",
            "date": "2019-01-31 10:10:55+00:00"
        },
        {
            "title": "Incentive Engineering for Concurrent Games",
            "text": "We consider the problem of incentivising desirable behaviours in multi-agent\nsystems by way of taxation schemes. Our study employs the concurrent games\nmodel: in this model, each agent is primarily motivated to seek the\nsatisfaction of a goal, expressed as a Linear Temporal Logic (LTL) formula;\nsecondarily, agents seek to minimise costs, where costs are imposed based on\nthe actions taken by agents in different states of the game. In this setting,\nwe consider an external principal who can influence agents' preferences by\nimposing taxes (additional costs) on the actions chosen by agents in different\nstates. The principal imposes taxation schemes to motivate agents to choose a\ncourse of action that will lead to the satisfaction of their goal, also\nexpressed as an LTL formula. However, taxation schemes are limited in their\nability to influence agents' preferences: an agent will always prefer to\nsatisfy its goal rather than otherwise, no matter what the costs. The\nfundamental question that we study is whether the principal can impose a\ntaxation scheme such that, in the resulting game, the principal's goal is\nsatisfied in at least one or all runs of the game that could arise by agents\nchoosing to follow game-theoretic equilibrium strategies. We consider two\ndifferent types of taxation schemes: in a static scheme, the same tax is\nimposed on a state-action profile pair in all circumstances, while in a dynamic\nscheme, the principal can choose to vary taxes depending on the circumstances.\nWe investigate the main game-theoretic properties of this model as well as the\ncomputational complexity of the relevant decision problems.",
            "url": "http://arxiv.org/abs/2307.05076v1",
            "id": "http://arxiv.org/abs/2307.05076v1",
            "date": "2023-07-11 07:19:24+00:00"
        },
        {
            "title": "Optimal loss-carry-forward taxation for L\u00e9vy risk processes stopped at general draw-down time",
            "text": "Motivated by Kyprianou and Zhou (2009), Wang and Hu (2012), Avram et al.\n(2017), Li et al. (2017) and Wang and Zhou (2018), we consider in this paper\nthe problem of maximizing the expected accumulated discounted tax payments of\nan insurance company, whose reserve process (before taxes are deducted) evolves\nas a spectrally negative L\\'{e}vy process with the usual exclusion of negative\nsubordinator or deterministic drift. Tax payments are collected according to\nthe very general loss-carry-forward tax system introduced in Kyprianou and Zhou\n(2009). To achieve a balance between taxation optimization and solvency, we\nconsider an interesting modified objective function by considering the expected\naccumulated discounted tax payments of the company until the general draw-down\ntime, instead of until the classical ruin time. The optimal tax return function\ntogether with the optimal tax strategy is derived, and some numerical examples\nare also provided.",
            "url": "http://arxiv.org/abs/1904.08029v1",
            "id": "http://arxiv.org/abs/1904.08029v1",
            "date": "2019-04-17 00:38:40+00:00"
        },
        {
            "title": "Bunching and Taxing Multidimensional Skills",
            "text": "We characterize optimal policy in a multidimensional nonlinear taxation model\nwith bunching. We develop an empirically relevant model with cognitive and\nmanual skills, firm heterogeneity, and labor market sorting. We first derive\ntwo conditions for the optimality of taxes that take into account bunching. The\nfirst condition $-$ a stochastic dominance optimal tax condition $-$ shows that\nat the optimum the schedule of benefits dominates the schedule of distortions\nin terms of second-order stochastic dominance. The second condition $-$ a\nglobal optimal tax formula $-$ provides a representation that balances the\nlocal costs and benefits of optimal taxation while explicitly accounting for\nglobal incentive constraints. Second, we use Legendre transformations to\nrepresent our problem as a linear program. This linearization allows us to\nsolve the model quantitatively and to precisely characterize bunching. At an\noptimum, 10 percent of workers is bunched. We introduce two notions of bunching\n$-$ blunt bunching and targeted bunching. Blunt bunching constitutes 30 percent\nof all bunching, occurs at the lowest regions of cognitive and manual skills,\nand lumps the allocations of these workers resulting in a significant\ndistortion. Targeted bunching constitutes 70 percent of all bunching and\nrecognizes the workers' comparative advantage. The planner separates workers on\ntheir dominant skill and bunches them on their weaker skill, thus mitigating\ndistortions along the dominant skill dimension.",
            "url": "http://arxiv.org/abs/2204.13481v2",
            "id": "http://arxiv.org/abs/2204.13481v2",
            "date": "2022-04-28 13:14:41+00:00"
        },
        {
            "title": "Tax Mechanisms and Gradient Flows",
            "text": "We demonstrate how a static optimal income taxation problem can be analyzed\nusing dynamical methods. Specifically, we show that the taxation problem is\nintimately connected to the heat equation. Our first result is a new property\nof the optimal tax which we call the fairness principle. The optimal tax at any\nincome is invariant under a family of properly adjusted Gaussian averages (the\nheat kernel) of the optimal taxes at other incomes. That is, the optimal tax at\na given income is equal to the weighted by the heat kernels average of optimal\ntaxes at other incomes and income densities. Moreover, this averaging happens\nat every scale tightly linked to each other providing a unified weighting\nscheme at all income ranges. The fairness principle arises not due to equality\nconsiderations but rather it represents an efficient way to smooth the burden\nof taxes and generated revenues across incomes. Just as nature wants to\ndistribute heat evenly, the optimal way for a government to raise revenues is\nto distribute the tax burden and raised revenues evenly among individuals. We\nthen construct a gradient flow of taxes -- a dynamic process changing the\nexisting tax system in the direction of the increase in tax revenues -- and\nshow that it takes the form of a heat equation. The fairness principle holds\nalso for the short-term asymptotics of the gradient flow, where the averaging\nis done over the current taxes. The gradient flow we consider can be viewed as\na continuous process of a reform of the nonlinear income tax schedule and thus\nunifies the variational approach to taxation and optimal taxation. We present\nseveral other characteristics of the gradient flow focusing on its smoothing\nproperties.",
            "url": "http://arxiv.org/abs/1904.13276v1",
            "id": "http://arxiv.org/abs/1904.13276v1",
            "date": "2019-04-30 14:27:53+00:00"
        },
        {
            "title": "Tax systems for sustainable economic development",
            "text": "A complete description of taxation systems that ensure sustainable economic\ndevelopment is given. These tax systems depend on production technologies and\ngross output volumes. Explicit formulas for such dependencies are found. In a\nsustainable economy, the value added either exceeds or is strictly less than\nthe value of the product produced. The latter is determined by the tax system.\nThe concept of perfect taxation systems is introduced and their explicit form\nis found. For perfect taxation systems, it is proved that the vector of gross\noutput should belong to the interior of the cone formed by the vectors of the\ncolumns of the total cost matrix. It is shown that under perfect taxation\nsystems the vector of gross output must satisfy a certain system of linear\nhomogeneous equations. It is shown, that under certain conditions there are tax\nsystems under which certain industries require subsidies for their existence.\nUnder such taxation systems, the industries that require subsidies are\nidentified. The family of all non negative solutions of the system of linear\nequations and inequalities is constructed, which allowed us to formulate a\ncriterion for describing all equilibrium states in which partial clearing of\nmarkets occurs.",
            "url": "http://arxiv.org/abs/2410.00505v1",
            "id": "http://arxiv.org/abs/2410.00505v1",
            "date": "2024-10-01 08:39:24+00:00"
        },
        {
            "title": "The Sustainable Future is now: a dynamic model to advance investments in PV and Energy Storage",
            "text": "We examine the relationship among photovoltaic (PV) investments, energy\nproduction, and environmental impact using a dynamic optimization model. Our\nfindings show that increasing investment in renewables supports both energy\ngeneration and ecological sustainability, with the optimal path depending on\npolicy priorities. Our analysis demonstrates that the economic and\ntechnological conditions for a transition to PV energy are already in place,\nchallenging the idea that renewables will only become competitive in the\nfuture. We also account for the fact that PV optimality conditions improve over\ntime as storage technology efficiency increases and production costs decrease.\nIn this perspective we find that energy storage may be a more effective policy\ntool than carbon taxation for cutting emissions, as it faces less political\nresistance and further strengthens the long-term viability of renewable energy.\nPolicy insights of the paper capture the evolving competitiveness of PV and its\nrole in accelerating the energy transition. They also provide policymakers with\nstrategies to align economic growth with long-term sustainability through\nrenewable energy investments.",
            "url": "http://arxiv.org/abs/2503.07131v1",
            "id": "http://arxiv.org/abs/2503.07131v1",
            "date": "2025-03-10 10:01:11+00:00"
        },
        {
            "title": "In Congestion Games, Taxes Achieve Optimal Approximation",
            "text": "In this work, we consider the problem of minimising the social cost in atomic\ncongestion games. For this problem, we provide tight computational lower bounds\nalong with taxation mechanisms yielding polynomial time algorithms with optimal\napproximation.\n  Perhaps surprisingly, our results show that indirect interventions, in the\nform of efficiently computed taxation mechanisms, yield the same performance\nachievable by the best polynomial time algorithm, even when the latter has full\ncontrol over the agents' actions. It follows that no other tractable approach\ngeared at incentivizing desirable system behavior can improve upon this result,\nregardless of whether it is based on taxations, coordination mechanisms,\ninformation provision, or any other principle. In short: Judiciously chosen\ntaxes achieve optimal approximation. Three technical contributions underpin\nthis conclusion. First, we show that computing the minimum social cost is\nNP-hard to approximate within a given factor depending solely on the admissible\nresource costs. Second, we design a tractable taxation mechanism whose\nefficiency (price of anarchy) matches this hardness factor, and thus is\nworst-case optimal. As these results extend to coarse correlated equilibria,\nany no-regret algorithm inherits the same performances, allowing us to devise\npolynomial time algorithms with optimal approximation.",
            "url": "http://arxiv.org/abs/2105.07480v2",
            "id": "http://arxiv.org/abs/2105.07480v2",
            "date": "2021-05-16 16:45:52+00:00"
        },
        {
            "title": "On growth-optimal tax rates and the issue of wealth inequalities",
            "text": "We introduce a highly stylized, yet non trivial model of the economy, with a\npublic and private sector coupled through a wealth tax and a redistribution\npolicy. The model can be fully solved analytically, and allows one to address\nthe question of optimal taxation and of wealth inequalities. We find that\naccording to the assumption made on the relative performance of public and\nprivate sectors, three situations are possible. Not surprisingly, the optimal\nwealth tax rate is either 0% for a deeply dysfunctional government and/or\nhighly productive private sector, or 100 % for a highly efficient public sector\nand/or debilitated/risk averse private investors. If the gap between the\npublic/private performance is moderate, there is an optimal positive wealth tax\nrate maximizing economic growth, even -- counter-intuitively -- when the\nprivate sector generates more growth. The compromise between profitable private\ninvestments and taxation however leads to a residual level of inequalities. The\nmechanism leading to an optimal growth rate is related the well-known\nexplore/exploit trade-off.",
            "url": "http://arxiv.org/abs/1508.00275v2",
            "id": "http://arxiv.org/abs/1508.00275v2",
            "date": "2015-08-02 19:24:20+00:00"
        },
        {
            "title": "A Taxation Perspective for Fair Re-ranking",
            "text": "Fair re-ranking aims to redistribute ranking slots among items more equitably\nto ensure responsibility and ethics. The exploration of redistribution problems\nhas a long history in economics, offering valuable insights for conceptualizing\nfair re-ranking as a taxation process. Such a formulation provides us with a\nfresh perspective to re-examine fair re-ranking and inspire the development of\nnew methods. From a taxation perspective, we theoretically demonstrate that\nmost previous fair re-ranking methods can be reformulated as an item-level tax\npolicy. Ideally, a good tax policy should be effective and conveniently\ncontrollable to adjust ranking resources. However, both empirical and\ntheoretical analyses indicate that the previous item-level tax policy cannot\nmeet two ideal controllable requirements: (1) continuity, ensuring minor\nchanges in tax rates result in small accuracy and fairness shifts; (2)\ncontrollability over accuracy loss, ensuring precise estimation of the accuracy\nloss under a specific tax rate. To overcome these challenges, we introduce a\nnew fair re-ranking method named Tax-rank, which levies taxes based on the\ndifference in utility between two items. Then, we efficiently optimize such an\nobjective by utilizing the Sinkhorn algorithm in optimal transport. Upon a\ncomprehensive analysis, Our model Tax-rank offers a superior tax policy for\nfair re-ranking, theoretically demonstrating both continuity and\ncontrollability over accuracy loss. Experimental results show that Tax-rank\noutperforms all state-of-the-art baselines in terms of effectiveness and\nefficiency on recommendation and advertising tasks.",
            "url": "http://arxiv.org/abs/2404.17826v1",
            "id": "http://arxiv.org/abs/2404.17826v1",
            "date": "2024-04-27 08:21:29+00:00"
        },
        {
            "title": "AI Work Quantization Model: Closed-System AI Computational Effort Metric",
            "text": "The rapid adoption of AI-driven automation in IoT environments, particularly\nin smart cities and industrial systems, necessitates a standardized approach to\nquantify AIs computational workload. Existing methodologies lack a consistent\nframework for measuring AI computational effort across diverse architectures,\nposing challenges in fair taxation models and energy-aware workload\nassessments. This study introduces the Closed-System AI Computational Effort\nMetric, a theoretical framework that quantifies real-time computational effort\nby incorporating input/output complexity, execution dynamics, and\nhardware-specific performance factors. The model ensures comparability between\nAI workloads across traditional CPUs and modern GPU/TPU accelerators,\nfacilitating standardized performance evaluations. Additionally, we propose an\nenergy-aware extension to assess AIs environmental impact, enabling\nsustainability-focused AI optimizations and equitable taxation models. Our\nfindings establish a direct correlation between AI workload and human\nproductivity, where 5 AI Workload Units equate to approximately 60 to 72 hours\nof human labor, exceeding a full-time workweek. By systematically linking AI\ncomputational effort to human labor, this framework enhances the understanding\nof AIs role in workforce automation, industrial efficiency, and sustainable\ncomputing. Future work will focus on refining the model through dynamic\nworkload adaptation, complexity normalization, and energy-aware AI cost\nestimation, further broadening its applicability in diverse AI-driven\necosystems.",
            "url": "http://arxiv.org/abs/2503.14515v1",
            "id": "http://arxiv.org/abs/2503.14515v1",
            "date": "2025-03-12 15:41:38+00:00"
        },
        {
            "title": "Optimal implementation delay of taxation with trade-off for L\u00e9vy risk Processes",
            "text": "In this paper we consider two problems on optimal implementation delay of\ntaxation with trade-off for spectrally negative L\\'{e}vy insurance risk\nprocesses. In the first case, we assume that an insurance company starts to pay\ntax when its surplus reaches a certain level $b$ and at the termination time of\nthe business there is a terminal value incurred to the company. The total\nexpected discounted value of tax payments plus the terminal value is maximized\nto obtain the optimal implementation level $b^*$. In the second case, the\ncompany still pays tax subject to an implementation level $a$ but with capital\ninjections to prevent bankruptcy. The total expected discounted value of tax\npayments minus the capital injection costs is maximized to obtain the optimal\nimplementation level $a^*$. Numerical examples are also given to illustrate the\nmain results in this paper.",
            "url": "http://arxiv.org/abs/1910.08158v1",
            "id": "http://arxiv.org/abs/1910.08158v1",
            "date": "2019-10-08 17:47:15+00:00"
        },
        {
            "title": "Optimal Taxation of Assets",
            "text": "The optimal taxation of assets requires attention to two concerns: 1) the\nelasticity of the supply of assets and 2) the impact of taxing assets on\ndistributional objectives. The most efficient way to attend to these two\nconcerns is to tax assets of different types separately, rather than having one\ntax on all assets. When assets are created by specialized effort rather than by\nsaving, as with innovations, discoveries of mineral deposits and development of\nunregulated natural monopolies, it is interesting to consider a regime in which\nthe government awards a prize for the creation of the asset and then collects\nthe remaining value of the asset in taxes. Analytically, the prize is like a\nwage after taxes. In this perspective, prizes are awarded based on a variation\non optimal taxation theory, while assets of different types are taxed in\ndivergent ways, depending on their characteristics. Some categories of assets\nare abolished.",
            "url": "http://arxiv.org/abs/2106.02861v1",
            "id": "http://arxiv.org/abs/2106.02861v1",
            "date": "2021-06-05 10:27:19+00:00"
        },
        {
            "title": "Kinetic models for optimal control of wealth inequalities",
            "text": "We introduce and discuss optimal control strategies for kinetic models for\nwealth distribution in a simple market economy, acting to minimize the variance\nof the wealth density among the population. Our analysis is based on a finite\ntime horizon approximation, or model predictive control, of the corresponding\ncontrol problem for the microscopic agents' dynamic and results in an\nalternative theoretical approach to the taxation and redistribution policy at a\nglobal level. It is shown that in general the control is able to modify the\nPareto index of the stationary solution of the corresponding Boltzmann kinetic\nequation, and that this modification can be exactly quantified. Connections\nbetween previous Fokker-Planck based models and taxation-redistribution\npolicies and the present approach are also discussed.",
            "url": "http://arxiv.org/abs/1803.02171v2",
            "id": "http://arxiv.org/abs/1803.02171v2",
            "date": "2018-03-06 13:46:34+00:00"
        },
        {
            "title": "Effect of tax dynamics on linearly growing processes under stochastic resetting: a possible economic model",
            "text": "We study a system of $N$ agents, whose wealth grows linearly, under the\neffect of stochastic resetting and interacting via a tax-like dynamics -- all\nagents donate a part of their wealth, which is, in turn, redistributed equally\namong all others. This mimics a socio-economic scenario where people have fixed\nincomes, suffer individual economic setbacks, and pay taxes to the state. The\nsystem always reaches a stationary state, which shows a trivial exponential\nwealth distribution in the absence of tax dynamics. The introduction of the tax\ndynamics leads to several interesting features in the stationary wealth\ndistribution. In particular, we analytically find that an increase in taxation\nfor a homogeneous system (where all agents are alike) results in a transition\nfrom a society where agents are most likely poor to another where rich agents\nare more common. We also study inhomogeneous systems, where the growth rates of\nthe agents are chosen from a distribution, and the taxation is proportional to\nthe individual growth rates. We find an optimal taxation, which produces a\ncomplete economic equality (average wealth is independent of the individual\ngrowth rates), beyond which there is a reverse disparity, where agents with low\ngrowth rates are more likely to be rich. We consider three income distributions\nobserved in the real world and show that they exhibit the same qualitative\nfeatures. Our analytical results are in the $N\\to\\infty$ limit and backed by\nnumerical simulations.",
            "url": "http://arxiv.org/abs/2202.13713v1",
            "id": "http://arxiv.org/abs/2202.13713v1",
            "date": "2022-02-28 12:14:08+00:00"
        },
        {
            "title": "Rational taxation in an open access fishery model",
            "text": "We consider a model of fishery management, where $n$ agents exploit a single\npopulation with strictly concave continuously differentiable growth function of\nVerhulst type. If the agent actions are coordinated and directed towards the\nmaximization of the discounted cooperative revenue, then the biomass stabilizes\nat the level, defined by the well known \"golden rule\". We show that for\nindependent myopic harvesting agents such optimal (or $\\varepsilon$-optimal)\ncooperative behavior can be stimulated by the proportional tax, depending on\nthe resource stock, and equal to the marginal value function of the cooperative\nproblem. To implement this taxation scheme we prove that the mentioned value\nfunction is strictly concave and continuously differentiable, although the\ninstantaneous individual revenues may be neither concave nor differentiable.",
            "url": "http://arxiv.org/abs/1602.07123v1",
            "id": "http://arxiv.org/abs/1602.07123v1",
            "date": "2016-02-23 11:30:33+00:00"
        },
        {
            "title": "Taxation Perspectives from Large Language Models: A Case Study on Additional Tax Penalties",
            "text": "How capable are large language models (LLMs) in the domain of taxation?\nAlthough numerous studies have explored the legal domain in general, research\ndedicated to taxation remain scarce. Moreover, the datasets used in these\nstudies are either simplified, failing to reflect the real-world complexities,\nor unavailable as open source. To address this gap, we introduce PLAT, a new\nbenchmark designed to assess the ability of LLMs to predict the legitimacy of\nadditional tax penalties. PLAT is constructed to evaluate LLMs' understanding\nof tax law, particularly in cases where resolving the issue requires more than\njust applying related statutes. Our experiments with six LLMs reveal that their\nbaseline capabilities are limited, especially when dealing with conflicting\nissues that demand a comprehensive understanding. However, we found that\nenabling retrieval, self-reasoning, and discussion among multiple agents with\nspecific role assignments, this limitation can be mitigated.",
            "url": "http://arxiv.org/abs/2503.03444v1",
            "id": "http://arxiv.org/abs/2503.03444v1",
            "date": "2025-03-05 12:24:20+00:00"
        },
        {
            "title": "The AI Economist: Optimal Economic Policy Design via Two-level Deep Reinforcement Learning",
            "text": "AI and reinforcement learning (RL) have improved many areas, but are not yet\nwidely adopted in economic policy design, mechanism design, or economics at\nlarge. At the same time, current economic methodology is limited by a lack of\ncounterfactual data, simplistic behavioral models, and limited opportunities to\nexperiment with policies and evaluate behavioral responses. Here we show that\nmachine-learning-based economic simulation is a powerful policy and mechanism\ndesign framework to overcome these limitations. The AI Economist is a\ntwo-level, deep RL framework that trains both agents and a social planner who\nco-adapt, providing a tractable solution to the highly unstable and novel\ntwo-level RL challenge. From a simple specification of an economy, we learn\nrational agent behaviors that adapt to learned planner policies and vice versa.\nWe demonstrate the efficacy of the AI Economist on the problem of optimal\ntaxation. In simple one-step economies, the AI Economist recovers the optimal\ntax policy of economic theory. In complex, dynamic economies, the AI Economist\nsubstantially improves both utilitarian social welfare and the trade-off\nbetween equality and productivity over baselines. It does so despite emergent\ntax-gaming strategies, while accounting for agent interactions and behavioral\nchange more accurately than economic theory. These results demonstrate for the\nfirst time that two-level, deep RL can be used for understanding and as a\ncomplement to theory for economic design, unlocking a new computational\nlearning-based approach to understanding economic policy.",
            "url": "http://arxiv.org/abs/2108.02755v1",
            "id": "http://arxiv.org/abs/2108.02755v1",
            "date": "2021-08-05 17:42:35+00:00"
        },
        {
            "title": "A Multi-LLM-Agent-Based Framework for Economic and Public Policy Analysis",
            "text": "This paper pioneers a novel approach to economic and public policy analysis\nby leveraging multiple Large Language Models (LLMs) as heterogeneous artificial\neconomic agents. We first evaluate five LLMs' economic decision-making\ncapabilities in solving two-period consumption allocation problems under two\ndistinct scenarios: with explicit utility functions and based on intuitive\nreasoning. While previous research has often simulated heterogeneity by solely\nvarying prompts, our approach harnesses the inherent variations in analytical\ncapabilities across different LLMs to model agents with diverse cognitive\ntraits. Building on these findings, we construct a Multi-LLM-Agent-Based (MLAB)\nframework by mapping these LLMs to specific educational groups and\ncorresponding income brackets. Using interest-income taxation as a case study,\nwe demonstrate how the MLAB framework can simulate policy impacts across\nheterogeneous agents, offering a promising new direction for economic and\npublic policy analysis by leveraging LLMs' human-like reasoning capabilities\nand computational power.",
            "url": "http://arxiv.org/abs/2502.16879v1",
            "id": "http://arxiv.org/abs/2502.16879v1",
            "date": "2025-02-24 06:27:07+00:00"
        },
        {
            "title": "Investigating Tax Evasion Emergence Using Dual Large Language Model and Deep Reinforcement Learning Powered Agent-based Simulation",
            "text": "Tax evasion, usually the largest component of an informal economy, is a\npersistent challenge over history with significant socio-economic implications.\nMany socio-economic studies investigate its dynamics, including influencing\nfactors, the role and influence of taxation policies, and the prediction of the\ntax evasion volume over time. These studies assumed such behavior is given, as\nobserved in the real world, neglecting the \"big bang\" of such activity in a\npopulation. To this end, computational economy studies adopted developments in\ncomputer simulations, in general, and recent innovations in artificial\nintelligence (AI), in particular, to simulate and study informal economy\nappearance in various socio-economic settings. This study presents a novel\ncomputational framework to examine the dynamics of tax evasion and the\nemergence of informal economic activity. Employing an agent-based simulation\npowered by Large Language Models and Deep Reinforcement Learning, the framework\nis uniquely designed to allow informal economic behaviors to emerge\norganically, without presupposing their existence or explicitly signaling\nagents about the possibility of evasion. This provides a rigorous approach for\nexploring the socio-economic determinants of compliance behavior. The\nexperimental design, comprising model validation and exploratory phases,\ndemonstrates the framework's robustness in replicating theoretical economic\nbehaviors. Findings indicate that individual personality traits, external\nnarratives, enforcement probabilities, and the perceived efficiency of public\ngoods provision significantly influence both the timing and extent of informal\neconomic activity. The results underscore that efficient public goods provision\nand robust enforcement mechanisms are complementary; neither alone is\nsufficient to curtail informal activity effectively.",
            "url": "http://arxiv.org/abs/2501.18177v1",
            "id": "http://arxiv.org/abs/2501.18177v1",
            "date": "2025-01-30 07:14:50+00:00"
        },
        {
            "title": "Synthesizing Interpretable Control Policies through Large Language Model Guided Search",
            "text": "The combination of Large Language Models (LLMs), systematic evaluation, and\nevolutionary algorithms has enabled breakthroughs in combinatorial optimization\nand scientific discovery. We propose to extend this powerful combination to the\ncontrol of dynamical systems, generating interpretable control policies capable\nof complex behaviors. With our novel method, we represent control policies as\nprograms in standard languages like Python. We evaluate candidate controllers\nin simulation and evolve them using a pre-trained LLM. Unlike conventional\nlearning-based control techniques, which rely on black-box neural networks to\nencode control policies, our approach enhances transparency and\ninterpretability. We still take advantage of the power of large AI models, but\nonly at the policy design phase, ensuring that all system components remain\ninterpretable and easily verifiable at runtime. Additionally, the use of\nstandard programming languages makes it straightforward for humans to finetune\nor adapt the controllers based on their expertise and intuition. We illustrate\nour method through its application to the synthesis of an interpretable control\npolicy for the pendulum swing-up and the ball in cup tasks. We make the code\navailable at\nhttps://github.com/muellerlab/synthesizing_interpretable_control_policies.git.",
            "url": "http://arxiv.org/abs/2410.05406v2",
            "id": "http://arxiv.org/abs/2410.05406v2",
            "date": "2024-10-07 18:12:20+00:00"
        },
        {
            "title": "On the Design of KL-Regularized Policy Gradient Algorithms for LLM Reasoning",
            "text": "Policy gradient algorithms have been successfully applied to enhance the\nreasoning capabilities of large language models (LLMs). Despite the widespread\nuse of Kullback-Leibler (KL) regularization in policy gradient algorithms to\nstabilize training, the systematic exploration of how different KL divergence\nformulations can be estimated and integrated into surrogate loss functions for\nonline reinforcement learning (RL) presents a nuanced and systematically\nexplorable design space. In this paper, we propose regularized policy gradient\n(RPG), a systematic framework for deriving and analyzing KL-regularized policy\ngradient methods in the online RL setting. We derive policy gradients and\ncorresponding surrogate loss functions for objectives regularized by both\nforward and reverse KL divergences, considering both normalized and\nunnormalized policy distributions. Furthermore, we present derivations for\nfully differentiable loss functions as well as REINFORCE-style gradient\nestimators, accommodating diverse algorithmic needs. We conduct extensive\nexperiments on RL for LLM reasoning using these methods, showing improved or\ncompetitive results in terms of training stability and performance compared to\nstrong baselines such as GRPO, REINFORCE++, and DAPO. The code is available at\nhttps://github.com/complex-reasoning/RPG.",
            "url": "http://arxiv.org/abs/2505.17508v1",
            "id": "http://arxiv.org/abs/2505.17508v1",
            "date": "2025-05-23 06:01:21+00:00"
        },
        {
            "title": "The Memorization Problem: Can We Trust LLMs' Economic Forecasts?",
            "text": "Large language models (LLMs) cannot be trusted for economic forecasts during\nperiods covered by their training data. We provide the first systematic\nevaluation of LLMs' memorization of economic and financial data, including\nmajor economic indicators, news headlines, stock returns, and conference calls.\nOur findings show that LLMs can perfectly recall the exact numerical values of\nkey economic variables from before their knowledge cutoff dates. This recall\nappears to be randomly distributed across different dates and data types. This\nselective perfect memory creates a fundamental issue -- when testing\nforecasting capabilities before their knowledge cutoff dates, we cannot\ndistinguish whether LLMs are forecasting or simply accessing memorized data.\nExplicit instructions to respect historical data boundaries fail to prevent\nLLMs from achieving recall-level accuracy in forecasting tasks. Further, LLMs\nseem exceptional at reconstructing masked entities from minimal contextual\nclues, suggesting that masking provides inadequate protection against motivated\nreasoning. Our findings raise concerns about using LLMs to forecast historical\ndata or backtest trading strategies, as their apparent predictive success may\nmerely reflect memorization rather than genuine economic insight. Any\napplication where future knowledge would change LLMs' outputs can be affected\nby memorization. In contrast, consistent with the absence of data\ncontamination, LLMs cannot recall data after their knowledge cutoff date.",
            "url": "http://arxiv.org/abs/2504.14765v1",
            "id": "http://arxiv.org/abs/2504.14765v1",
            "date": "2025-04-20 23:36:27+00:00"
        },
        {
            "title": "Disagreement Spillovers",
            "text": "As US political party leaders increasingly take stances both on economic and\ncultural (i.e., social policy) issues, the economic views of opposite cultural\ngroups are growing apart. This paper explores a novel explanation for this\nphenomenon. I provide experimental evidence that adding social policy content\nto a policy message pushes those disagreeing with the social policy to disagree\nalso with the economic content of the message. As my results suggest regular\ndeviations from Bayesian explanations, I propose a model of identity-based\nbelief updating that predicts the main regularities found in the experiment.\nFinally, I shed light on opinion leaders' incentives to strengthen the\nassociation between social policy and economic policy views.",
            "url": "http://arxiv.org/abs/2411.11186v2",
            "id": "http://arxiv.org/abs/2411.11186v2",
            "date": "2024-11-17 22:23:42+00:00"
        },
        {
            "title": "Reasoning Like an Economist: Post-Training on Economic Problems Induces Strategic Generalization in LLMs",
            "text": "Directly training Large Language Models (LLMs) for Multi-Agent Systems (MAS)\nremains challenging due to intricate reward modeling, dynamic agent\ninteractions, and demanding generalization requirements. This paper explores\nwhether post-training techniques, specifically Supervised Fine-Tuning (SFT) and\nReinforcement Learning with Verifiable Rewards (RLVR), can effectively\n$\\textit{generalize}$ to multi-agent scenarios. We use economic reasoning as a\ntestbed, leveraging its strong foundations in mathematics and game theory, its\ndemand for structured analytical reasoning, and its relevance to real-world\napplications such as market design, resource allocation, and policy analysis.\nWe introduce $\\textbf{Recon}$ ($\\textbf{R}$easoning like an\n$\\textbf{ECON}$omist), a 7B-parameter open-source LLM post-trained on a\nhand-curated dataset of 2,100 high-quality economic reasoning problems.\nComprehensive evaluation on economic reasoning benchmarks and multi-agent games\nreveals clear improvements in structured reasoning and economic rationality.\nThese results underscore the promise of domain-aligned post-training for\nenhancing reasoning and agent alignment, shedding light on the roles of SFT and\nRL in shaping model behavior. Code is available at\nhttps://github.com/MasterZhou1/Recon .",
            "url": "http://arxiv.org/abs/2506.00577v1",
            "id": "http://arxiv.org/abs/2506.00577v1",
            "date": "2025-05-31 14:22:40+00:00"
        },
        {
            "title": "Walk Before You Run! Concise LLM Reasoning via Reinforcement Learning",
            "text": "As test-time scaling becomes a pivotal research frontier in Large Language\nModels (LLMs) development, contemporary and advanced post-training\nmethodologies increasingly focus on extending the generation length of long\nChain-of-Thought (CoT) responses to enhance reasoning capabilities toward\nDeepSeek R1-like performance. However, recent studies reveal a persistent\noverthinking phenomenon in state-of-the-art reasoning models, manifesting as\nexcessive redundancy or repetitive thinking patterns in long CoT responses. To\naddress this issue, in this paper, we propose a simple yet effective two-stage\nreinforcement learning framework for achieving concise reasoning in LLMs, named\nConciseR. Specifically, the first stage, using more training steps, aims to\nincentivize the model's reasoning capabilities via Group Relative Policy\nOptimization with clip-higher and dynamic sampling components (GRPO++), and the\nsecond stage, using fewer training steps, explicitly enforces conciseness and\nimproves efficiency via Length-aware Group Relative Policy Optimization\n(L-GRPO). Significantly, ConciseR only optimizes response length once all\nrollouts of a sample are correct, following the \"walk before you run\"\nprinciple. Extensive experimental results demonstrate that our ConciseR model,\nwhich generates more concise CoT reasoning responses, outperforms recent\nstate-of-the-art reasoning models with zero RL paradigm across AIME 2024,\nMATH-500, AMC 2023, Minerva, and Olympiad benchmarks.",
            "url": "http://arxiv.org/abs/2505.21178v1",
            "id": "http://arxiv.org/abs/2505.21178v1",
            "date": "2025-05-27 13:29:51+00:00"
        },
        {
            "title": "Synthesizing Access Control Policies using Large Language Models",
            "text": "Cloud compute systems allow administrators to write access control policies\nthat govern access to private data. While policies are written in convenient\nlanguages, such as AWS Identity and Access Management Policy Language, manually\nwritten policies often become complex and error prone. In this paper, we\ninvestigate whether and how well Large Language Models (LLMs) can be used to\nsynthesize access control policies. Our investigation focuses on the task of\ntaking an access control request specification and zero-shot prompting LLMs to\nsynthesize a well-formed access control policy which correctly adheres to the\nrequest specification. We consider two scenarios, one which the request\nspecification is given as a concrete list of requests to be allowed or denied,\nand another in which a natural language description is used to specify sets of\nrequests to be allowed or denied. We then argue that for zero-shot prompting,\nmore precise and structured prompts using a syntax based approach are necessary\nand experimentally show preliminary results validating our approach.",
            "url": "http://arxiv.org/abs/2503.11573v1",
            "id": "http://arxiv.org/abs/2503.11573v1",
            "date": "2025-03-14 16:40:25+00:00"
        },
        {
            "title": "When Experimental Economics Meets Large Language Models: Tactics with Evidence",
            "text": "Advancements in large language models (LLMs) have sparked a growing interest\nin measuring and understanding their behavior through experimental economics.\nHowever, there is still a lack of established guidelines for designing economic\nexperiments for LLMs. By combining principles from experimental economics with\ninsights from LLM research in artificial intelligence, we outline and discuss\neight practical tactics for conducting experiments with LLMs. We further\nperform two sets of experiments to demonstrate the significance of these\ntactics. Our study enhances the design, replicability, and generalizability of\nLLM experiments, and broadens the scope of experimental economics in the\ndigital age.",
            "url": "http://arxiv.org/abs/2505.21371v1",
            "id": "http://arxiv.org/abs/2505.21371v1",
            "date": "2025-05-27 16:01:07+00:00"
        },
        {
            "title": "Soft Policy Optimization: Online Off-Policy RL for Sequence Models",
            "text": "RL-based post-training of language models is almost exclusively done using\non-policy methods such as PPO. These methods cannot learn from arbitrary\nsequences such as those produced earlier in training, in earlier runs, by human\nexperts or other policies, or by decoding and exploration methods. This results\nin severe sample inefficiency and exploration difficulties, as well as a\npotential loss of diversity in the policy responses. Moreover, asynchronous PPO\nimplementations require frequent and costly model transfers, and typically use\nvalue models which require a large amount of memory. In this paper we introduce\nSoft Policy Optimization (SPO), a simple, scalable and principled Soft RL\nmethod for sequence model policies that can learn from arbitrary online and\noffline trajectories and does not require a separate value model. In\nexperiments on code contests, we shows that SPO outperforms PPO on pass@10, is\nsignificantly faster and more memory efficient, is able to benefit from\noff-policy data, enjoys improved stability, and learns more diverse (i.e. soft)\npolicies.",
            "url": "http://arxiv.org/abs/2503.05453v1",
            "id": "http://arxiv.org/abs/2503.05453v1",
            "date": "2025-03-07 14:23:40+00:00"
        },
        {
            "title": "ForPKG: A Framework for Constructing Forestry Policy Knowledge Graph and Application Analysis",
            "text": "A policy knowledge graph can provide decision support for tasks such as\nproject compliance, policy analysis, and intelligent question answering, and\ncan also serve as an external knowledge base to assist the reasoning process of\nrelated large language models. Although there have been many related works on\nknowledge graphs, there is currently a lack of research on the construction\nmethods of policy knowledge graphs. This paper, focusing on the forestry field,\ndesigns a complete policy knowledge graph construction framework, including:\nfirstly, proposing a fine-grained forestry policy domain ontology; then,\nproposing an unsupervised policy information extraction method, and finally,\nconstructing a complete forestry policy knowledge graph. The experimental\nresults show that the proposed ontology has good expressiveness and\nextensibility, and the policy information extraction method proposed in this\npaper achieves better results than other unsupervised methods. Furthermore, by\nanalyzing the application of the knowledge graph in the\nretrieval-augmented-generation task of the large language models, the practical\napplication value of the knowledge graph in the era of large language models is\nconfirmed. The knowledge graph resource will be released on an open-source\nplatform and can serve as the basic knowledge base for forestry policy-related\nintelligent systems. It can also be used for academic research. In addition,\nthis study can provide reference and guidance for the construction of policy\nknowledge graphs in other fields. Our data is provided on Github\nhttps://github.com/luozhongze/ForPKG.",
            "url": "http://arxiv.org/abs/2411.11090v2",
            "id": "http://arxiv.org/abs/2411.11090v2",
            "date": "2024-11-17 14:45:52+00:00"
        },
        {
            "title": "Real-time Monitoring of Economic Shocks using Company Websites",
            "text": "Understanding the effects of economic shocks on firms is critical for\nanalyzing economic growth and resilience. We introduce a Web-Based Affectedness\nIndicator (WAI), a general-purpose tool for real-time monitoring of economic\ndisruptions across diverse contexts. By leveraging Large Language Model (LLM)\nassisted classification and information extraction on texts from over five\nmillion company websites, WAI quantifies the degree and nature of firms'\nresponses to external shocks. Using the COVID-19 pandemic as a specific\napplication, we show that WAI is highly correlated with pandemic containment\nmeasures and reliably predicts firm performance. Unlike traditional data\nsources, WAI provides timely firm-level information across industries and\ngeographies worldwide that would otherwise be unavailable due to institutional\nand data availability constraints. This methodology offers significant\npotential for monitoring and mitigating the impact of technological, political,\nfinancial, health or environmental crises, and represents a transformative tool\nfor adaptive policy-making and economic resilience.",
            "url": "http://arxiv.org/abs/2502.17161v1",
            "id": "http://arxiv.org/abs/2502.17161v1",
            "date": "2025-02-24 13:56:27+00:00"
        },
        {
            "title": "Trading off performance and human oversight in algorithmic policy: evidence from Danish college admissions",
            "text": "Student dropout is a significant concern for educational institutions due to\nits social and economic impact, driving the need for risk prediction systems to\nidentify at-risk students before enrollment. We explore the accuracy of such\nsystems in the context of higher education by predicting degree completion\nbefore admission, with potential applications for prioritizing admissions\ndecisions. Using a large-scale dataset from Danish higher education admissions,\nwe demonstrate that advanced sequential AI models offer more precise and fair\npredictions compared to current practices that rely on either high school grade\npoint averages or human judgment. These models not only improve accuracy but\nalso outperform simpler models, even when the simpler models use protected\nsociodemographic attributes. Importantly, our predictions reveal how certain\nstudent profiles are better matched with specific programs and fields,\nsuggesting potential efficiency and welfare gains in public policy. We estimate\nthat even the use of simple AI models to guide admissions decisions,\nparticularly in response to a newly implemented nationwide policy reducing\nadmissions by 10 percent, could yield significant economic benefits. However,\nthis improvement would come at the cost of reduced human oversight and lower\ntransparency. Our findings underscore both the potential and challenges of\nincorporating advanced AI into educational policymaking.",
            "url": "http://arxiv.org/abs/2411.15348v2",
            "id": "http://arxiv.org/abs/2411.15348v2",
            "date": "2024-11-22 21:12:54+00:00"
        },
        {
            "title": "Evaluating and Aligning Human Economic Risk Preferences in LLMs",
            "text": "Large Language Models (LLMs) are increasingly used in decision-making\nscenarios that involve risk assessment, yet their alignment with human economic\nrationality remains unclear. In this study, we investigate whether LLMs exhibit\nrisk preferences consistent with human expectations across different personas.\nSpecifically, we assess whether LLM-generated responses reflect appropriate\nlevels of risk aversion or risk-seeking behavior based on individual's persona.\nOur results reveal that while LLMs make reasonable decisions in simplified,\npersonalized risk contexts, their performance declines in more complex economic\ndecision-making tasks. To address this, we propose an alignment method designed\nto enhance LLM adherence to persona-specific risk preferences. Our approach\nimproves the economic rationality of LLMs in risk-related applications,\noffering a step toward more human-aligned AI decision-making.",
            "url": "http://arxiv.org/abs/2503.06646v1",
            "id": "http://arxiv.org/abs/2503.06646v1",
            "date": "2025-03-09 14:47:31+00:00"
        },
        {
            "title": "Words that Move Markets- Quantifying the Impact of RBI's Monetary Policy Communications on Indian Financial Market",
            "text": "We analyze the impact of the Reserve Bank of India's (RBI) monetary policy\ncommunications on Indian financial market from April 2014 to June 2024 using\nadvanced natural language processing techniques. Employing BERTopic for topic\nmodeling and a fine-tuned RoBERTa model for sentiment analysis, we assess how\nvariations in sentiment across different economic topics affect the stock\nmarket. Our findings indicate that dovish sentiment generally leads to declines\nin equity markets, particularly in topics related to the interest rate policy\nframework and economic growth, suggesting that market participants interpret\ndovish language as signaling economic weakness rather than policy easing.\nConversely, dovish sentiment regarding foreign exchange reserves management has\na positive impact on equity market. These results highlight the importance of\ntopic-specific communication strategies for central banks in emerging markets.",
            "url": "http://arxiv.org/abs/2411.04808v1",
            "id": "http://arxiv.org/abs/2411.04808v1",
            "date": "2024-11-07 15:44:46+00:00"
        },
        {
            "title": "Language Models Trained to do Arithmetic Predict Human Risky and Intertemporal Choice",
            "text": "The observed similarities in the behavior of humans and Large Language Models\n(LLMs) have prompted researchers to consider the potential of using LLMs as\nmodels of human cognition. However, several significant challenges must be\naddressed before LLMs can be legitimately regarded as cognitive models. For\ninstance, LLMs are trained on far more data than humans typically encounter,\nand may have been directly trained on human data in specific cognitive tasks or\naligned with human preferences. Consequently, the origins of these behavioral\nsimilarities are not well understood. In this paper, we propose a novel way to\nenhance the utility of LLMs as cognitive models. This approach involves (i)\nleveraging computationally equivalent tasks that both an LLM and a rational\nagent need to master for solving a cognitive problem and (ii) examining the\nspecific task distributions required for an LLM to exhibit human-like\nbehaviors. We apply this approach to decision-making -- specifically risky and\nintertemporal choice -- where the key computationally equivalent task is the\narithmetic of expected value calculations. We show that an LLM pretrained on an\necologically valid arithmetic dataset, which we call Arithmetic-GPT, predicts\nhuman behavior better than many traditional cognitive models. Pretraining LLMs\non ecologically valid arithmetic datasets is sufficient to produce a strong\ncorrespondence between these models and human decision-making. Our results also\nsuggest that LLMs used as cognitive models should be carefully investigated via\nablation studies of the pretraining data.",
            "url": "http://arxiv.org/abs/2405.19313v2",
            "id": "http://arxiv.org/abs/2405.19313v2",
            "date": "2024-05-29 17:37:14+00:00"
        },
        {
            "title": "Automating Governing Knowledge Commons and Contextual Integrity (GKC-CI) Privacy Policy Annotations with Large Language Models",
            "text": "Identifying contextual integrity (CI) and governing knowledge commons (GKC)\nparameters in privacy policy texts can facilitate normative privacy analysis.\nHowever, GKC-CI annotation has heretofore required manual or crowdsourced\neffort. This paper demonstrates that high-accuracy GKC-CI parameter annotation\nof privacy policies can be performed automatically using large language models.\nWe fine-tune 50 open-source and proprietary models on 21,588 ground truth\nGKC-CI annotations from 16 privacy policies. Our best performing model has an\naccuracy of 90.65%, which is comparable to the accuracy of experts on the same\ntask. We apply our best performing model to 456 privacy policies from a variety\nof online services, demonstrating the effectiveness of scaling GKC-CI\nannotation for privacy policy exploration and analysis. We publicly release our\nmodel training code, training and testing data, an annotation visualizer, and\nall annotated policies for future GKC-CI research.",
            "url": "http://arxiv.org/abs/2311.02192v3",
            "id": "http://arxiv.org/abs/2311.02192v3",
            "date": "2023-11-03 18:49:05+00:00"
        },
        {
            "title": "Adaptive Augmentation Policy Optimization with LLM Feedback",
            "text": "Data augmentation is a critical component of deep learning pipelines,\nenhancing model generalization by increasing dataset diversity. Traditional\naugmentation strategies rely on manually designed transformations, stochastic\nsampling, or automated search-based approaches. Although automated methods\nimprove performance, they often require extensive computational resources and\nare tailored to specific datasets. In this work, we propose a Large Language\nModel (LLM)-guided augmentation optimization strategy that refines augmentation\npolicies based on model performance feedback. We introduce two approaches: (1)\nLLM-Guided Augmentation Policy Optimization, where augmentation policies are\nselected by an LLM prior to training and iteratively refined across multiple\ntraining cycles, and (2) Adaptive LLM-Guided Augmentation Policy Optimization,\nwhere policies adapt in real-time based on performance metrics. This\nin-training approach eliminates the need for full model retraining before\nreceiving LLM feedback, thereby reducing computational costs while improving\nperformance. Our methodology employs an LLM to dynamically select augmentation\ntransformations based on dataset characteristics, model architecture, and prior\ntraining outcomes. Unlike traditional search-based methods, our approach\nleverages the contextual knowledge of LLMs, particularly in specialized domains\nlike medical imaging, to recommend augmentation strategies tailored to\ndomain-specific data. We evaluate our approach on multiple domain-specific\nimage classification datasets where augmentation is key to model robustness.\nResults show that LLM-guided augmentation optimization outperforms traditional\nmethods, improving model accuracy. These findings highlight the potential of\nLLMs in automating and adapting deep learning training workflows.",
            "url": "http://arxiv.org/abs/2410.13453v3",
            "id": "http://arxiv.org/abs/2410.13453v3",
            "date": "2024-10-17 11:26:10+00:00"
        },
        {
            "title": "Trust, Experience, and Innovation: Key Factors Shaping American Attitudes About AI",
            "text": "A large survey of American adults explored the complex landscape of attitudes\ntowards artificial intelligence (AI). It explored the degree of concern\nregarding specific potential outcomes of the new advances in AI technology and\ncorrelates of these concerns. Key variables associated with the direction and\nintensity of concern include prior experience using a large language model such\nas ChatGPT, general trust in science, adherence to the precautionary principle\nversus support for unrestricted innovation, and demographic factors such as\ngender. By analyzing these relationships, the paper provides valuable insights\ninto the American public's response to AI that are particularly important in\nthe development of policy to regulate or further encourage its development.",
            "url": "http://arxiv.org/abs/2503.05815v1",
            "id": "http://arxiv.org/abs/2503.05815v1",
            "date": "2025-03-04 16:08:20+00:00"
        },
        {
            "title": "The Ecological System of Innovation: A New Architectural Framework for a Functional Evidence-Based Platform for Science and Innovation Policy",
            "text": "Models on innovation, for the most part, do not include a comprehensive and\nend-to-end view. Most innovation policy attention seems to be focused on the\ncapacity to innovate and on input factors such as R&D investment, scientific\ninstitutions, human resources and capital. Such inputs frequently serve as\nproxies for innovativeness and are correlated with intermediate outputs such as\npatent counts and outcomes such as GDP per capita. While this kind of analysis\nis generally indicative of innovative behaviour, it is less useful in terms of\ndiscriminating causality and what drives successful strategy or public policy\ninterventions. This situation has led to the developing of new frameworks for\nthe innovation system led by National Science and Technology Policy Centres\nacross the globe. These new models of innovation are variously referred to as\nthe National Innovation Ecosystem. There is, however, a fundamental question\nthat needs to be answered: what elements should an innovation policy include,\nand how should such policies be implemented? This paper attempts to answer this\nquestion.",
            "url": "http://arxiv.org/abs/2106.15479v1",
            "id": "http://arxiv.org/abs/2106.15479v1",
            "date": "2021-06-24 11:05:08+00:00"
        },
        {
            "title": "Can Large Language Models Trade? Testing Financial Theories with LLM Agents in Market Simulations",
            "text": "This paper presents a realistic simulated stock market where large language\nmodels (LLMs) act as heterogeneous competing trading agents. The open-source\nframework incorporates a persistent order book with market and limit orders,\npartial fills, dividends, and equilibrium clearing alongside agents with varied\nstrategies, information sets, and endowments. Agents submit standardized\ndecisions using structured outputs and function calls while expressing their\nreasoning in natural language. Three findings emerge: First, LLMs demonstrate\nconsistent strategy adherence and can function as value investors, momentum\ntraders, or market makers per their instructions. Second, market dynamics\nexhibit features of real financial markets, including price discovery, bubbles,\nunderreaction, and strategic liquidity provision. Third, the framework enables\nanalysis of LLMs' responses to varying market conditions, similar to partial\ndependence plots in machine-learning interpretability. The framework allows\nsimulating financial theories without closed-form solutions, creating\nexperimental designs that would be costly with human participants, and\nestablishing how prompts can generate correlated behaviors affecting market\nstability.",
            "url": "http://arxiv.org/abs/2504.10789v1",
            "id": "http://arxiv.org/abs/2504.10789v1",
            "date": "2025-04-15 01:18:36+00:00"
        },
        {
            "title": "AI Policy Projector: Grounding LLM Policy Design in Iterative Mapmaking",
            "text": "Whether a large language model policy is an explicit constitution or an\nimplicit reward model, it is challenging to assess coverage over the unbounded\nset of real-world situations that a policy must contend with. We introduce an\nAI policy design process inspired by mapmaking, which has developed tactics for\nvisualizing and iterating on maps even when full coverage is not possible. With\nPolicy Projector, policy designers can survey the landscape of model\ninput-output pairs, define custom regions (e.g., \"violence\"), and navigate\nthese regions with rules that can be applied to LLM outputs (e.g., if output\ncontains \"violence\" and \"graphic details,\" then rewrite without \"graphic\ndetails\"). Policy Projector supports interactive policy authoring using LLM\nclassification and steering and a map visualization reflecting the policy\ndesigner's work. In an evaluation with 12 AI safety experts, our system helps\npolicy designers to address problematic model behaviors extending beyond an\nexisting, comprehensive harm taxonomy.",
            "url": "http://arxiv.org/abs/2409.18203v1",
            "id": "http://arxiv.org/abs/2409.18203v1",
            "date": "2024-09-26 18:34:16+00:00"
        },
        {
            "title": "Agentic Workflows for Economic Research: Design and Implementation",
            "text": "This paper introduces a methodology based on agentic workflows for economic\nresearch that leverages Large Language Models (LLMs) and multimodal AI to\nenhance research efficiency and reproducibility. Our approach features\nautonomous and iterative processes covering the entire research lifecycle--from\nideation and literature review to economic modeling and data processing,\nempirical analysis and result interpretation--with strategic human oversight.\nThe workflow architecture comprises specialized agents with clearly defined\nroles, structured inter-agent communication protocols, systematic error\nescalation pathways, and adaptive mechanisms that respond to changing research\ndemand. Human-in-the-loop (HITL) checkpoints are strategically integrated to\nensure methodological validity and ethical compliance. We demonstrate the\npractical implementation of our framework using Microsoft's open-source\nplatform, AutoGen, presenting experimental examples that highlight both the\ncurrent capabilities and future potential of agentic workflows in improving\neconomic research.",
            "url": "http://arxiv.org/abs/2504.09736v1",
            "id": "http://arxiv.org/abs/2504.09736v1",
            "date": "2025-04-13 21:54:47+00:00"
        },
        {
            "title": "Escalation Risks from Language Models in Military and Diplomatic Decision-Making",
            "text": "Governments are increasingly considering integrating autonomous AI agents in\nhigh-stakes military and foreign-policy decision-making, especially with the\nemergence of advanced generative AI models like GPT-4. Our work aims to\nscrutinize the behavior of multiple AI agents in simulated wargames,\nspecifically focusing on their predilection to take escalatory actions that may\nexacerbate multilateral conflicts. Drawing on political science and\ninternational relations literature about escalation dynamics, we design a novel\nwargame simulation and scoring framework to assess the escalation risks of\nactions taken by these agents in different scenarios. Contrary to prior\nstudies, our research provides both qualitative and quantitative insights and\nfocuses on large language models (LLMs). We find that all five studied\noff-the-shelf LLMs show forms of escalation and difficult-to-predict escalation\npatterns. We observe that models tend to develop arms-race dynamics, leading to\ngreater conflict, and in rare cases, even to the deployment of nuclear weapons.\nQualitatively, we also collect the models' reported reasonings for chosen\nactions and observe worrying justifications based on deterrence and\nfirst-strike tactics. Given the high stakes of military and foreign-policy\ncontexts, we recommend further examination and cautious consideration before\ndeploying autonomous language model agents for strategic military or diplomatic\ndecision-making.",
            "url": "http://arxiv.org/abs/2401.03408v1",
            "id": "http://arxiv.org/abs/2401.03408v1",
            "date": "2024-01-07 07:59:10+00:00"
        }
    ],
    "query": "Your task is to write a Related Works section for an academic paper given the paper's abstract. Your response should provide the Related Works section and references. Only include references from arXiv that are published before {03 Jun 2025}. Mention them in a separate, numbered reference list at the end and use the reference numbers to provide in-line citations in the Related Works section for all claims referring to a source (e.g., description of source [3]. Further details [6][7][8][9][10].) Each in-line citation must consist of a single reference number within a pair of brackets. Do not use any other citation format. Do not exceed 600 words for the related works section. Here is the paper abstract:\\n{Economic inequality is a global challenge, intensifying disparities in\\neducation, healthcare, and social stability. Traditional systems like the U.S.\\nfederal income tax reduce inequality but lack adaptability. Although models\\nlike the Saez Optimal Taxation adjust dynamically, they fail to address\\ntaxpayer heterogeneity and irrational behavior. This study introduces TaxAgent,\\na novel integration of large language models (LLMs) with agent-based modeling\\n(ABM) to design adaptive tax policies. In our macroeconomic simulation,\\nheterogeneous H-Agents (households) simulate real-world taxpayer behaviors\\nwhile the TaxAgent (government) utilizes LLMs to iteratively optimize tax\\nrates, balancing equity and productivity. Benchmarked against Saez Optimal\\nTaxation, U.S. federal income taxes, and free markets, TaxAgent achieves\\nsuperior equity-efficiency trade-offs. This research offers a novel taxation\\nsolution and a scalable, data-driven framework for fiscal policy evaluation.}.",
    "usage": {
        "total_tokens": 28807,
        "cache_hits": 0,
        "total_cost_usd_dollar": 0.069602
    }
}